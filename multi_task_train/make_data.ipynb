{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset\n",
    "* task_kind 1桁目　タスクの種類\n",
    "* data種別 2桁目　データの種類 0=image 1=in_text 2=out_text\n",
    "* index 小数点以下　データのindex\n",
    "* 例: 20.0123 タスク1のimageの123番目のdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#タスク種別\n",
    "task_kind = 3 # 1, 2, 3\n",
    "#タスクデータの数\n",
    "dataset_len = 300 #100,1100,300\n",
    "\n",
    "#データの種類\n",
    "data_kind =3 #0:image, 1:in_text, 2:out_text\n",
    "index_range = 10000\n",
    "\n",
    "with open(f\"./dataset_{task_kind}.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in range(dataset_len):\n",
    "        data = [task_kind*10+j+i/index_range for j in range(data_kind)]\n",
    "        writer.writerow(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = []\n",
    "        with open(csv_file, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                self.data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [torch.tensor([float(data)]) for data in self.data[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = MyDataset(\"./dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10.]), tensor([11.]), tensor([12.])]\n",
      "[tensor([10.0001]), tensor([11.0001]), tensor([12.0001])]\n",
      "[tensor([10.0002]), tensor([11.0002]), tensor([12.0002])]\n",
      "[tensor([10.0003]), tensor([11.0003]), tensor([12.0003])]\n",
      "[tensor([10.0004]), tensor([11.0004]), tensor([12.0004])]\n",
      "[tensor([10.0005]), tensor([11.0005]), tensor([12.0005])]\n",
      "[tensor([10.0006]), tensor([11.0006]), tensor([12.0006])]\n",
      "[tensor([10.0007]), tensor([11.0007]), tensor([12.0007])]\n",
      "[tensor([10.0008]), tensor([11.0008]), tensor([12.0008])]\n",
      "[tensor([10.0009]), tensor([11.0009]), tensor([12.0009])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[10.0000],\n",
      "        [10.0001],\n",
      "        [10.0002],\n",
      "        [10.0003],\n",
      "        [10.0004],\n",
      "        [10.0005],\n",
      "        [10.0006],\n",
      "        [10.0007],\n",
      "        [10.0008],\n",
      "        [10.0009]]), tensor([[11.0000],\n",
      "        [11.0001],\n",
      "        [11.0002],\n",
      "        [11.0003],\n",
      "        [11.0004],\n",
      "        [11.0005],\n",
      "        [11.0006],\n",
      "        [11.0007],\n",
      "        [11.0008],\n",
      "        [11.0009]]), tensor([[12.0000],\n",
      "        [12.0001],\n",
      "        [12.0002],\n",
      "        [12.0003],\n",
      "        [12.0004],\n",
      "        [12.0005],\n",
      "        [12.0006],\n",
      "        [12.0007],\n",
      "        [12.0008],\n",
      "        [12.0009]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset_1, batch_size=10, shuffle=False)\n",
    "dataloader_iter = iter(dataloader)\n",
    "print(next(dataloader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex_module import ExModel\n",
    "model = ExModel(None)\n",
    "data = next(dataloader_iter)\n",
    "out = model(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data1 = [[1],[2],[3]]\n",
    "data2 = [[4],[5],[6],[7]]\n",
    "print(torch.cat([torch.tensor(data1), torch.tensor(data2)],dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KLab_MultiModalModel-Zh2ecsZR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
