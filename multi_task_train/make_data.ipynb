{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset\n",
    "* task_kind 1桁目　タスクの種類\n",
    "* data種別 2桁目　データの種類 0=image 1=in_text 2=out_text\n",
    "* index 小数点以下　データのindex\n",
    "* 例: 20.0123 タスク1のimageの123番目のdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#タスク種別\n",
    "task_kind = 3 # 1, 2, 3\n",
    "#タスクデータの数\n",
    "dataset_len = 300 #100,1100,300\n",
    "\n",
    "#データの種類\n",
    "data_kind =3 #0:image, 1:in_text, 2:out_text\n",
    "index_range = 10000\n",
    "\n",
    "with open(f\"./dataset_{task_kind}.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in range(dataset_len):\n",
    "        data = [task_kind*10+j+i/index_range for j in range(data_kind)]\n",
    "        writer.writerow(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = []\n",
    "        with open(csv_file, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                self.data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [torch.tensor([float(data)]) for data in self.data[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = MyDataset(\"./dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10.]), tensor([11.]), tensor([12.])]\n",
      "[tensor([10.0001]), tensor([11.0001]), tensor([12.0001])]\n",
      "[tensor([10.0002]), tensor([11.0002]), tensor([12.0002])]\n",
      "[tensor([10.0003]), tensor([11.0003]), tensor([12.0003])]\n",
      "[tensor([10.0004]), tensor([11.0004]), tensor([12.0004])]\n",
      "[tensor([10.0005]), tensor([11.0005]), tensor([12.0005])]\n",
      "[tensor([10.0006]), tensor([11.0006]), tensor([12.0006])]\n",
      "[tensor([10.0007]), tensor([11.0007]), tensor([12.0007])]\n",
      "[tensor([10.0008]), tensor([11.0008]), tensor([12.0008])]\n",
      "[tensor([10.0009]), tensor([11.0009]), tensor([12.0009])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[10.0000],\n",
      "        [10.0001],\n",
      "        [10.0002],\n",
      "        [10.0003],\n",
      "        [10.0004],\n",
      "        [10.0005],\n",
      "        [10.0006],\n",
      "        [10.0007],\n",
      "        [10.0008],\n",
      "        [10.0009]]), tensor([[11.0000],\n",
      "        [11.0001],\n",
      "        [11.0002],\n",
      "        [11.0003],\n",
      "        [11.0004],\n",
      "        [11.0005],\n",
      "        [11.0006],\n",
      "        [11.0007],\n",
      "        [11.0008],\n",
      "        [11.0009]]), tensor([[12.0000],\n",
      "        [12.0001],\n",
      "        [12.0002],\n",
      "        [12.0003],\n",
      "        [12.0004],\n",
      "        [12.0005],\n",
      "        [12.0006],\n",
      "        [12.0007],\n",
      "        [12.0008],\n",
      "        [12.0009]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset_1, batch_size=10, shuffle=False)\n",
    "dataloader_iter = iter(dataloader)\n",
    "print(next(dataloader_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex_module import ExModel\n",
    "model = ExModel(None)\n",
    "data = next(dataloader_iter)\n",
    "out = model(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data1 = [[1],[2],[3]]\n",
    "data2 = [[4],[5],[6],[7]]\n",
    "print(torch.cat([torch.tensor(data1), torch.tensor(data2)],dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ChainDataset\n",
    "from ex_module import MyDataset,MyChainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = MyDataset(\"./dataset_1.csv\")\n",
    "dataset_2 = MyDataset(\"./dataset_2.csv\")\n",
    "dataset_3 = MyDataset(\"./dataset_3.csv\")\n",
    "\n",
    "dataset = MyChainDataset([dataset_1, dataset_2, dataset_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True,num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[30.0199],\n",
      "        [20.0449],\n",
      "        [30.0097],\n",
      "        [20.0364]]), tensor([[31.0199],\n",
      "        [21.0449],\n",
      "        [31.0097],\n",
      "        [21.0364]]), tensor([[32.0199],\n",
      "        [22.0449],\n",
      "        [32.0097],\n",
      "        [22.0364]])]\n",
      "[tensor([[30.0026],\n",
      "        [20.0920],\n",
      "        [20.0107],\n",
      "        [20.0210]]), tensor([[31.0026],\n",
      "        [21.0920],\n",
      "        [21.0107],\n",
      "        [21.0210]]), tensor([[32.0026],\n",
      "        [22.0920],\n",
      "        [22.0107],\n",
      "        [22.0210]])]\n",
      "[tensor([[20.0607],\n",
      "        [20.0588],\n",
      "        [20.0843],\n",
      "        [30.0298]]), tensor([[21.0607],\n",
      "        [21.0588],\n",
      "        [21.0843],\n",
      "        [31.0298]]), tensor([[22.0607],\n",
      "        [22.0588],\n",
      "        [22.0843],\n",
      "        [32.0298]])]\n",
      "[tensor([[20.0393],\n",
      "        [20.0751],\n",
      "        [10.0041],\n",
      "        [20.0572]]), tensor([[21.0393],\n",
      "        [21.0751],\n",
      "        [11.0041],\n",
      "        [21.0572]]), tensor([[22.0393],\n",
      "        [22.0751],\n",
      "        [12.0041],\n",
      "        [22.0572]])]\n",
      "[tensor([[20.0209],\n",
      "        [10.0001],\n",
      "        [20.0556],\n",
      "        [20.0159]]), tensor([[21.0209],\n",
      "        [11.0001],\n",
      "        [21.0556],\n",
      "        [21.0159]]), tensor([[22.0209],\n",
      "        [12.0001],\n",
      "        [22.0556],\n",
      "        [22.0159]])]\n",
      "[tensor([[20.1063],\n",
      "        [20.0807],\n",
      "        [20.0568],\n",
      "        [20.0857]]), tensor([[21.1063],\n",
      "        [21.0807],\n",
      "        [21.0568],\n",
      "        [21.0857]]), tensor([[22.1063],\n",
      "        [22.0807],\n",
      "        [22.0568],\n",
      "        [22.0857]])]\n",
      "[tensor([[20.0852],\n",
      "        [20.0484],\n",
      "        [30.0281],\n",
      "        [20.0006]]), tensor([[21.0852],\n",
      "        [21.0484],\n",
      "        [31.0281],\n",
      "        [21.0006]]), tensor([[22.0852],\n",
      "        [22.0484],\n",
      "        [32.0281],\n",
      "        [22.0006]])]\n",
      "[tensor([[10.0068],\n",
      "        [20.0389],\n",
      "        [20.0238],\n",
      "        [30.0153]]), tensor([[11.0068],\n",
      "        [21.0389],\n",
      "        [21.0238],\n",
      "        [31.0153]]), tensor([[12.0068],\n",
      "        [22.0389],\n",
      "        [22.0238],\n",
      "        [32.0153]])]\n",
      "[tensor([[20.0247],\n",
      "        [20.1046],\n",
      "        [20.0337],\n",
      "        [30.0020]]), tensor([[21.0247],\n",
      "        [21.1046],\n",
      "        [21.0337],\n",
      "        [31.0020]]), tensor([[22.0247],\n",
      "        [22.1046],\n",
      "        [22.0337],\n",
      "        [32.0020]])]\n",
      "[tensor([[20.0154],\n",
      "        [20.0287],\n",
      "        [20.0797],\n",
      "        [20.0979]]), tensor([[21.0154],\n",
      "        [21.0287],\n",
      "        [21.0797],\n",
      "        [21.0979]]), tensor([[22.0154],\n",
      "        [22.0287],\n",
      "        [22.0797],\n",
      "        [22.0979]])]\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "for i in range(10):\n",
    "    print(next(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset[\u001b[39m1500\u001b[39;49m]\n",
      "File \u001b[0;32m~/WorkSpace/KLab_MultiModalModel/multi_task_train/ex_module.py:63\u001b[0m, in \u001b[0;36mMyChainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         idx \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KLab_MultiModalModel-Zh2ecsZR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
