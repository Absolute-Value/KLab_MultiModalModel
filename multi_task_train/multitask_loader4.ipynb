{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #データセット名\n",
    "# task_kind = 5 # 1, 2, 3, 4, 5\n",
    "# #タスクデータの数\n",
    "# dataset_len = 200 #100,1100,300, 500, 200\n",
    "\n",
    "# #データの種類\n",
    "# data_kind =3 #0:image, 1:in_text, 2:out_text\n",
    "# index_range = 10000\n",
    "\n",
    "# with open(f\"./dataset_{task_kind}.csv\", \"w\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i in range(dataset_len):\n",
    "#         data = [task_kind*10+j+i/index_range for j in range(data_kind)]\n",
    "#         writer.writerow(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,ConcatDataset\n",
    "import torch\n",
    "import csv\n",
    "from typing import Callable, Optional, Tuple\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DistributedSampler\n",
    "import math\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###持っているタスクから一回ずつ取り出す\n",
    "#multitask_collate_fn = lambda sample_list: sample_list\n",
    "def default_each_task_collate_fn(batch):\n",
    "    # list[image,in_text,out_text]が入力される\n",
    "    sample_list = [[] for _ in range(len(batch[0]))]\n",
    "    for data in batch:\n",
    "        for i, sample in enumerate(data):\n",
    "            sample_list[i].append(sample)\n",
    "    return sample_list\n",
    "\n",
    "\n",
    "def default_multi_task_collate_fn(sample_per_task_list):\n",
    "    if type(sample_per_task_list[0]) == list:\n",
    "        next_sample = [[] for _ in range(len(sample_per_task_list[0]))]\n",
    "        for sample_list in sample_per_task_list:\n",
    "            for i, sample in enumerate(sample_list):\n",
    "                next_sample[i].extend(sample) #[imageA,imageB,imageC],[in_textA,in_textB,in_textC],[out_textA,out_textB,out_textC]]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    next_sample = [torch.stack(sample) for sample in next_sample]\n",
    "    return next_sample\n",
    "\n",
    "\n",
    "class MultiTaskDataIterator:\n",
    "    def __init__(self, dataloader_list, step_list, multi_data_collate_fn=None) -> None:\n",
    "        self.iter_list = [iter(dataloader) for dataloader in dataloader_list]\n",
    "        self.min_step = min(step_list)\n",
    "        self.step = 0\n",
    "        self.multi_task_collate_fn = multi_data_collate_fn\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.step == self.min_step:\n",
    "            raise StopIteration\n",
    "\n",
    "        next_sample_list = [next(iter) for iter in self.iter_list]  # [taskA,taskB,taskC]\n",
    "\n",
    "        if self.multi_task_collate_fn is None:\n",
    "            next_sample = default_multi_task_collate_fn(\n",
    "                next_sample_list\n",
    "            )  # [imageA,imageB,imageC],[in_textA,in_textB,in_textC],[out_textA,out_textB,out_textC]]\n",
    "        else:\n",
    "            next_sample = self.multi_task_collate_fn(next_sample_list)  # [taskA,taskB,taskC]\n",
    "        self.step += 1\n",
    "        return next_sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "\n",
    "\n",
    "class MultiTaskDataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dict: dict[str, DataLoader],\n",
    "        batch_size_dict: dict[str, int],\n",
    "        each_task_collate_fn_dict: dict[str, Callable] = None,\n",
    "        multi_task_collate_fn=None,\n",
    "        is_ddp=False,\n",
    "        seed=0,\n",
    "        loader_drop_last=False,\n",
    "        sampler_drop_last=False,\n",
    "        **dataloader_args,\n",
    "    ) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            dataset_dict (dict[str,DataLoader]): {taskA:Dataset,taskB:Dataset,taskC:Dataset}のようなdict\n",
    "            batch_size_dict (_type_): ｛taskA:10,taskB:20,taskC:10｝のようなdict\n",
    "            each_task_collate_fn_dict (dict[str,function], optional): {taskA:collate_fnA,taskB:collate_fnB,task:C,collate_fnC}のようなdict.タスクごとのデーターローダー Defaults to None.\n",
    "            multi_task_collate_fn (_type_, optional): すべてのタスクからのバッチを統合する関数 Defaults to None.\n",
    "            is_ddp (bool, optional): DDPか否か Defaults to False.\n",
    "            seed (int, optional): 乱数シード Defaults to 0.\n",
    "        \"\"\"\n",
    "\n",
    "        dataset_dict_keys = dataset_dict.keys()\n",
    "        if is_ddp:\n",
    "            distributed_keys = [\"num_replicas\", \"rank\", \"shuffle\"]\n",
    "            distributed_args_dict = {}\n",
    "            for key in distributed_keys:\n",
    "                if key in dataloader_args:\n",
    "                    distributed_args_dict[key] = dataloader_args[key]\n",
    "                    del dataloader_args[key]\n",
    "\n",
    "            self.distributed_sampler_dict = {\n",
    "                key: DistributedSampler(dataset_dict[key], seed=seed, drop_last=sampler_drop_last, **distributed_args_dict) for key in dataset_dict_keys\n",
    "            }\n",
    "        else:\n",
    "            self.distributed_sampler_dict = {key: None for key in dataset_dict_keys}\n",
    "\n",
    "        if each_task_collate_fn_dict is None:\n",
    "            each_task_collate_fn_dict = {key: default_each_task_collate_fn for key in dataset_dict_keys}\n",
    "\n",
    "        def seed_worker(worker_id):\n",
    "            worker_seed = torch.initial_seed() % 2**32\n",
    "            np.random.seed(worker_seed)\n",
    "            random.seed(worker_seed)\n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "\n",
    "        self.dataloader_list = [\n",
    "            DataLoader(\n",
    "                dataset_dict[key],\n",
    "                batch_size_dict[key],\n",
    "                collate_fn=each_task_collate_fn_dict[key],\n",
    "                sampler=self.distributed_sampler_dict[key],\n",
    "                worker_init_fn=seed_worker,\n",
    "                generator=g,\n",
    "                drop_last=loader_drop_last,\n",
    "                **dataloader_args,\n",
    "            )\n",
    "            for key in dataset_dict_keys\n",
    "        ]\n",
    "        self.step_list = [len(dataloader) for dataloader in self.dataloader_list]\n",
    "        self.min_step = min(self.step_list)\n",
    "        self.multi_task_collate_fn = multi_task_collate_fn\n",
    "\n",
    "    def __iter__(self):\n",
    "        return MultiTaskDataIterator(self.dataloader_list, self.step_list, self.multi_task_collate_fn)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "\n",
    "    def set_epoch(self, epoch: int):\n",
    "        for sampler in self.distributed_sampler_dict.values():\n",
    "            sampler.set_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingIterator(object):\n",
    "    \"\"\"Wrapper around an iterable that maintains the iteration count.\n",
    "\n",
    "    Args:\n",
    "        iterable (iterable): iterable to wrap\n",
    "        start (int): starting iteration count. Note that this doesn't\n",
    "            actually advance the iterator.\n",
    "        total (int): override the iterator length returned by ``__len``.\n",
    "            This can be used to truncate *iterator*.\n",
    "\n",
    "    Attributes:\n",
    "        n (int): number of elements consumed from this iterator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iterable, start=None, total=None):\n",
    "        self._itr = iter(iterable)\n",
    "        self.n = start or getattr(iterable, \"n\", 0)\n",
    "        self.total = total if total is not None else self.n + len(iterable)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if not self.has_next():\n",
    "            raise StopIteration\n",
    "        try:\n",
    "            x = next(self._itr)\n",
    "        except StopIteration:\n",
    "            raise IndexError(\n",
    "                f\"Iterator expected to have length {self.total}, \"\n",
    "                f\"but exhausted at position {self.n}.\"\n",
    "            )\n",
    "        self.n += 1\n",
    "        return x\n",
    "\n",
    "    def has_next(self):\n",
    "        \"\"\"Whether the iterator has been exhausted.\"\"\"\n",
    "        return self.n < self.total\n",
    "\n",
    "    def skip(self, n):\n",
    "        \"\"\"Fast-forward the iterator by skipping n elements.\"\"\"\n",
    "        for _ in range(n):\n",
    "            next(self)\n",
    "        return self\n",
    "\n",
    "    def take(self, n):\n",
    "        \"\"\"Truncate the iterator to n elements at most.\"\"\"\n",
    "        self.total = min(self.total, n)\n",
    "        # Propagate this change to the underlying iterator\n",
    "        if hasattr(self._itr, \"take\"):\n",
    "            self._itr.take(max(n - self.n, 0))\n",
    "        return self\n",
    "\n",
    "class GroupedIterator(CountingIterator):\n",
    "    \"\"\"Wrapper around an iterable that returns groups (chunks) of items.\n",
    "\n",
    "    Args:\n",
    "        iterable (iterable): iterable to wrap\n",
    "        chunk_size (int): size of each chunk\n",
    "        skip_remainder_batch (bool, optional): if set, discard the last grouped batch in\n",
    "          each training epoch, as the last grouped batch is usually smaller than\n",
    "                local_batch_size * distributed_word_size * chunk_size (default: ``False``).\n",
    "    Attributes:\n",
    "        n (int): number of elements consumed from this iterator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iterable, chunk_size, skip_remainder_batch=False):\n",
    "        if skip_remainder_batch:\n",
    "            total_num_itrs = int(math.floor(len(iterable) / float(chunk_size)))\n",
    "            #logger.info(\n",
    "            #    f\"skip final residual batch, grouped total_num_itrs = {total_num_itrs}\"\n",
    "            #)\n",
    "        else:\n",
    "            #raise NotImplementedError\n",
    "            total_num_itrs = int(math.ceil(len(iterable) / float(chunk_size)))\n",
    "            #logger.info(f\"grouped total_num_itrs = {total_num_itrs}\")\n",
    "\n",
    "        itr = _chunk_iterator(iterable, chunk_size, skip_remainder_batch)\n",
    "        super().__init__(\n",
    "            itr,\n",
    "            start=int(math.ceil(getattr(iterable, \"n\", 0) / float(chunk_size))),\n",
    "            total=total_num_itrs,\n",
    "        )\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        if skip_remainder_batch:\n",
    "            self.take(total_num_itrs)\n",
    "            # TODO: [Hack] Here the grouped iterator modifies the base iterator size so that\n",
    "            # training can move into the next epoch once the grouped iterator is exhausted.\n",
    "            # Double-check this implementation in case unexpected behavior occurs.\n",
    "            iterable.take(total_num_itrs * chunk_size)\n",
    "\n",
    "\n",
    "def _chunk_iterator(itr, chunk_size, skip_remainder_batch=False):\n",
    "    chunk = []\n",
    "    for x in itr:\n",
    "        chunk.append(x)\n",
    "        if len(chunk) == chunk_size:\n",
    "            yield chunk\n",
    "            chunk = []\n",
    "    if not skip_remainder_batch and len(chunk) > 0:\n",
    "        yield chunk\n",
    "        \n",
    "def default_each_task_collate_fn(batch):\n",
    "    # list[image,in_text,out_text]が入力される\n",
    "    sample_list = [[] for _ in range(len(batch[0]))]\n",
    "    for data in batch:\n",
    "        for i, sample in enumerate(data):\n",
    "            sample_list[i].append(sample)\n",
    "    return sample_list\n",
    "\n",
    "\n",
    "def default_multi_task_collate_fn(sample_per_task_list):\n",
    "    if type(sample_per_task_list[0]) == list:\n",
    "        next_sample = [[] for _ in range(len(sample_per_task_list[0]))]\n",
    "        for sample_list in sample_per_task_list:\n",
    "            for i, sample in enumerate(sample_list):\n",
    "                next_sample[i].extend(sample) #[imageA,imageB,imageC],[in_textA,in_textB,in_textC],[out_textA,out_textB,out_textC]]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    next_sample = [torch.stack(sample) for sample in next_sample]\n",
    "    return next_sample\n",
    "\n",
    "\n",
    "class MultiTaskDataIterator:\n",
    "    def __init__(self, dataloader_list, step_list, sample_num_list) -> None:\n",
    "        self.dataloader_list = dataloader_list\n",
    "        self.min_step = min(step_list)\n",
    "        self.step = 0\n",
    "        self.sample_num_list = sample_num_list\n",
    "        self.start = 0\n",
    "        self.grouped_iterator_list = [iter(GroupedIterator(CountingIterator(dataloader,0), sample_num,skip_remainder_batch=True)) for dataloader,sample_num in zip(self.dataloader_list,self.sample_num_list)]\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.step == self.min_step:\n",
    "            raise StopIteration\n",
    "\n",
    "        next_sample_list = itertools.chain.from_iterable([next(iter) for iter in self.grouped_iterator_list])  # [taskA,taskB,taskC]\n",
    "\n",
    "        self.step += 1\n",
    "        return next_sample_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "\n",
    "\n",
    "class MultiTaskDataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dict: dict[str, DataLoader],\n",
    "        batch_size_dict: dict[str, int],\n",
    "        each_task_collate_fn_dict: dict[str, Callable] = None,\n",
    "        each_task_sample_num_dict: dict[str, int] = None,\n",
    "        is_ddp=False,\n",
    "        seed=0,\n",
    "        loader_drop_last=False,\n",
    "        sampler_drop_last=False,\n",
    "        **dataloader_args,\n",
    "    ) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            dataset_dict (dict[str,DataLoader]): {taskA:Dataset,taskB:Dataset,taskC:Dataset}のようなdict\n",
    "            batch_size_dict (_type_): ｛taskA:10,taskB:20,taskC:10｝のようなdict\n",
    "            each_task_collate_fn_dict (dict[str,function], optional): {taskA:collate_fnA,taskB:collate_fnB,task:C,collate_fnC}のようなdict.タスクごとのデーターローダー Defaults to None.\n",
    "            multi_task_collate_fn (_type_, optional): すべてのタスクからのバッチを統合する関数 Defaults to None.\n",
    "            is_ddp (bool, optional): DDPか否か Defaults to False.\n",
    "            seed (int, optional): 乱数シード Defaults to 0.\n",
    "        \"\"\"\n",
    "\n",
    "        dataset_dict_keys = dataset_dict.keys()\n",
    "        if is_ddp:\n",
    "            distributed_keys = [\"num_replicas\", \"rank\", \"shuffle\"]\n",
    "            distributed_args_dict = {}\n",
    "            for key in distributed_keys:\n",
    "                if key in dataloader_args:\n",
    "                    distributed_args_dict[key] = dataloader_args[key]\n",
    "                    del dataloader_args[key]\n",
    "\n",
    "            self.distributed_sampler_dict = {\n",
    "                key: DistributedSampler(dataset_dict[key], seed=seed, drop_last=sampler_drop_last, **distributed_args_dict) for key in dataset_dict_keys\n",
    "            }\n",
    "        else:\n",
    "            self.distributed_sampler_dict = {key: None for key in dataset_dict_keys}\n",
    "\n",
    "        if each_task_collate_fn_dict is None:\n",
    "            each_task_collate_fn_dict = {key: default_each_task_collate_fn for key in dataset_dict_keys}\n",
    "\n",
    "        def seed_worker(worker_id):\n",
    "            worker_seed = torch.initial_seed() % 2**32\n",
    "            np.random.seed(worker_seed)\n",
    "            random.seed(worker_seed)\n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "\n",
    "        self.dataloader_list = [\n",
    "            DataLoader(\n",
    "                dataset_dict[key],\n",
    "                batch_size_dict[key],\n",
    "                collate_fn=each_task_collate_fn_dict[key],\n",
    "                sampler=self.distributed_sampler_dict[key],\n",
    "                worker_init_fn=seed_worker,\n",
    "                generator=g,\n",
    "                drop_last=loader_drop_last,\n",
    "                **dataloader_args,\n",
    "            )\n",
    "            for key in dataset_dict_keys\n",
    "        ]\n",
    "        \n",
    "        self.sample_num_list = [each_task_sample_num_dict[key] for key in dataset_dict_keys]\n",
    "        self.step_list = [int(math.floor(len(dataloader) / float(sample_num))) for sample_num,dataloader in zip(self.sample_num_list,self.dataloader_list)]\n",
    "        self.min_step = min(self.step_list)\n",
    "        #self.multi_task_collate_fn = multi_task_collate_fn\n",
    "\n",
    "    def __iter__(self):\n",
    "        return MultiTaskDataIterator(self.dataloader_list, self.step_list, self.sample_num_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "\n",
    "    def set_epoch(self, epoch: int):\n",
    "        for sampler in self.distributed_sampler_dict.values():\n",
    "            sampler.set_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_10 = range(10)\n",
    "iter_10 = iter(range_10)\n",
    "chunk_size = 3\n",
    "skip_remainder_batch = True\n",
    "counting_range_10 = CountingIterator(range_10,0)\n",
    "counting_range_10.take(len(counting_range_10)-1)\n",
    "grouped_range_10 = GroupedIterator(counting_range_10, chunk_size, skip_remainder_batch)\n",
    "#最後まで読んだら初期化しなしないといけない\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "next\n",
      "[3, 4, 5]\n",
      "next\n",
      "[6, 7, 8]\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "for sample in grouped_range_10:\n",
    "    print(sample)\n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb セル 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39;49m(grouped_iter_10))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnext\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb セル 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_next():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu4090-10/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/multitask_loader4.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_itr)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grouped_iter_10 = iter(grouped_range_10)\n",
    "\n",
    "print(\"iter\")\n",
    "for i in range(5):\n",
    "    print(next(grouped_iter_10))\n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = []\n",
    "        with open(csv_file, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                self.data.append(row)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [torch.tensor([float(data)]) for data in self.data[idx]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path):\n",
    "    return MyDataset(path)\n",
    "\n",
    "def get_data(dataset_name_dict):\n",
    "    dataset_dict = {\n",
    "        key: ConcatDataset([get_dataset(f\"./dataset_{task_kind}.csv\") for task_kind in dataset_name_dict[key]]) for key in dataset_name_dict.keys()\n",
    "    }\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([50.0199]), tensor([51.0199]), tensor([52.0199])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 1000, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python multi_task_train/jsonargs.py '{\"taskA\":[\"1\",\"4\"],\"taskB\":[\"2\"],\"taskC\":[\"3\",\"5\"]}'\n",
    "dataset_name_dict = {\"taskA\":[\"1\",\"4\"], #1:100, 4:500 = 600\n",
    "                \"taskB\":[\"2\"], #2: 1100\n",
    "                \"taskC\":[\"3\",\"5\"]} # 3:300, 5:200 = 500\n",
    "\n",
    "dataset_dict = get_data(dataset_name_dict)\n",
    "print(dataset_dict[\"taskC\"][499])\n",
    "# batch_size_dict = {\"taskA\": 10, \"taskB\": 109, \"taskC\": 5} \n",
    "# sample_num_dict = {\"taskA\": 2, \"taskB\": 1, \"taskC\": 4}\n",
    "# #Bのバッチは1～9stepは109個、10stepは10個\n",
    "\n",
    "batch_size_dict = {\"taskA\": 10, \"taskB\": 20, \"taskC\": 5}\n",
    "sample_num_dict = {\"taskA\": 2, \"taskB\": 2, \"taskC\": 4}\n",
    "# inex0 20,40,20\n",
    "# index24 500,1000,500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = MultiTaskDataLoader(dataset_dict,batch_size_dict,None,each_task_sample_num_dict=sample_num_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python multi_task_train/jsonargs.py '{\"taskA\":[\"1\",\"4\"],\"taskB\":[\"2\"],\"taskC\":[\"3\",\"5\"]}'\n",
    "dataset_name_dict = {\"taskA\":[\"1\",\"4\"], #1:100, 4:500 = 600\n",
    "                \"taskB\":[\"2\"], #2: 1100\n",
    "                \"taskC\":[\"3\",\"5\"]} # 3:300, 5:200 = 500\n",
    "\n",
    "batch_size_dict = {\"taskA\": 10, \"taskB\": 20, \"taskC\": 5}\n",
    "sample_num_dict = {\"taskA\": 2, \"taskB\": 2, \"taskC\": 4}\n",
    "# inex0 20,40,20\n",
    "# index24 500,1000,500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "index:0\n",
      "[[tensor([10.]), tensor([10.0001]), tensor([10.0002]), tensor([10.0003]), tensor([10.0004]), tensor([10.0005]), tensor([10.0006]), tensor([10.0007]), tensor([10.0008]), tensor([10.0009])], [tensor([11.]), tensor([11.0001]), tensor([11.0002]), tensor([11.0003]), tensor([11.0004]), tensor([11.0005]), tensor([11.0006]), tensor([11.0007]), tensor([11.0008]), tensor([11.0009])], [tensor([12.]), tensor([12.0001]), tensor([12.0002]), tensor([12.0003]), tensor([12.0004]), tensor([12.0005]), tensor([12.0006]), tensor([12.0007]), tensor([12.0008]), tensor([12.0009])]]\n",
      "[[tensor([10.0010]), tensor([10.0011]), tensor([10.0012]), tensor([10.0013]), tensor([10.0014]), tensor([10.0015]), tensor([10.0016]), tensor([10.0017]), tensor([10.0018]), tensor([10.0019])], [tensor([11.0010]), tensor([11.0011]), tensor([11.0012]), tensor([11.0013]), tensor([11.0014]), tensor([11.0015]), tensor([11.0016]), tensor([11.0017]), tensor([11.0018]), tensor([11.0019])], [tensor([12.0010]), tensor([12.0011]), tensor([12.0012]), tensor([12.0013]), tensor([12.0014]), tensor([12.0015]), tensor([12.0016]), tensor([12.0017]), tensor([12.0018]), tensor([12.0019])]]\n",
      "[[tensor([20.]), tensor([20.0001]), tensor([20.0002]), tensor([20.0003]), tensor([20.0004]), tensor([20.0005]), tensor([20.0006]), tensor([20.0007]), tensor([20.0008]), tensor([20.0009]), tensor([20.0010]), tensor([20.0011]), tensor([20.0012]), tensor([20.0013]), tensor([20.0014]), tensor([20.0015]), tensor([20.0016]), tensor([20.0017]), tensor([20.0018]), tensor([20.0019])], [tensor([21.]), tensor([21.0001]), tensor([21.0002]), tensor([21.0003]), tensor([21.0004]), tensor([21.0005]), tensor([21.0006]), tensor([21.0007]), tensor([21.0008]), tensor([21.0009]), tensor([21.0010]), tensor([21.0011]), tensor([21.0012]), tensor([21.0013]), tensor([21.0014]), tensor([21.0015]), tensor([21.0016]), tensor([21.0017]), tensor([21.0018]), tensor([21.0019])], [tensor([22.]), tensor([22.0001]), tensor([22.0002]), tensor([22.0003]), tensor([22.0004]), tensor([22.0005]), tensor([22.0006]), tensor([22.0007]), tensor([22.0008]), tensor([22.0009]), tensor([22.0010]), tensor([22.0011]), tensor([22.0012]), tensor([22.0013]), tensor([22.0014]), tensor([22.0015]), tensor([22.0016]), tensor([22.0017]), tensor([22.0018]), tensor([22.0019])]]\n",
      "[[tensor([20.0020]), tensor([20.0021]), tensor([20.0022]), tensor([20.0023]), tensor([20.0024]), tensor([20.0025]), tensor([20.0026]), tensor([20.0027]), tensor([20.0028]), tensor([20.0029]), tensor([20.0030]), tensor([20.0031]), tensor([20.0032]), tensor([20.0033]), tensor([20.0034]), tensor([20.0035]), tensor([20.0036]), tensor([20.0037]), tensor([20.0038]), tensor([20.0039])], [tensor([21.0020]), tensor([21.0021]), tensor([21.0022]), tensor([21.0023]), tensor([21.0024]), tensor([21.0025]), tensor([21.0026]), tensor([21.0027]), tensor([21.0028]), tensor([21.0029]), tensor([21.0030]), tensor([21.0031]), tensor([21.0032]), tensor([21.0033]), tensor([21.0034]), tensor([21.0035]), tensor([21.0036]), tensor([21.0037]), tensor([21.0038]), tensor([21.0039])], [tensor([22.0020]), tensor([22.0021]), tensor([22.0022]), tensor([22.0023]), tensor([22.0024]), tensor([22.0025]), tensor([22.0026]), tensor([22.0027]), tensor([22.0028]), tensor([22.0029]), tensor([22.0030]), tensor([22.0031]), tensor([22.0032]), tensor([22.0033]), tensor([22.0034]), tensor([22.0035]), tensor([22.0036]), tensor([22.0037]), tensor([22.0038]), tensor([22.0039])]]\n",
      "[[tensor([30.]), tensor([30.0001]), tensor([30.0002]), tensor([30.0003]), tensor([30.0004])], [tensor([31.]), tensor([31.0001]), tensor([31.0002]), tensor([31.0003]), tensor([31.0004])], [tensor([32.]), tensor([32.0001]), tensor([32.0002]), tensor([32.0003]), tensor([32.0004])]]\n",
      "[[tensor([30.0005]), tensor([30.0006]), tensor([30.0007]), tensor([30.0008]), tensor([30.0009])], [tensor([31.0005]), tensor([31.0006]), tensor([31.0007]), tensor([31.0008]), tensor([31.0009])], [tensor([32.0005]), tensor([32.0006]), tensor([32.0007]), tensor([32.0008]), tensor([32.0009])]]\n",
      "[[tensor([30.0010]), tensor([30.0011]), tensor([30.0012]), tensor([30.0013]), tensor([30.0014])], [tensor([31.0010]), tensor([31.0011]), tensor([31.0012]), tensor([31.0013]), tensor([31.0014])], [tensor([32.0010]), tensor([32.0011]), tensor([32.0012]), tensor([32.0013]), tensor([32.0014])]]\n",
      "[[tensor([30.0015]), tensor([30.0016]), tensor([30.0017]), tensor([30.0018]), tensor([30.0019])], [tensor([31.0015]), tensor([31.0016]), tensor([31.0017]), tensor([31.0018]), tensor([31.0019])], [tensor([32.0015]), tensor([32.0016]), tensor([32.0017]), tensor([32.0018]), tensor([32.0019])]]\n",
      "index:24\n",
      "[[tensor([40.0380]), tensor([40.0381]), tensor([40.0382]), tensor([40.0383]), tensor([40.0384]), tensor([40.0385]), tensor([40.0386]), tensor([40.0387]), tensor([40.0388]), tensor([40.0389])], [tensor([41.0380]), tensor([41.0381]), tensor([41.0382]), tensor([41.0383]), tensor([41.0384]), tensor([41.0385]), tensor([41.0386]), tensor([41.0387]), tensor([41.0388]), tensor([41.0389])], [tensor([42.0380]), tensor([42.0381]), tensor([42.0382]), tensor([42.0383]), tensor([42.0384]), tensor([42.0385]), tensor([42.0386]), tensor([42.0387]), tensor([42.0388]), tensor([42.0389])]]\n",
      "[[tensor([40.0390]), tensor([40.0391]), tensor([40.0392]), tensor([40.0393]), tensor([40.0394]), tensor([40.0395]), tensor([40.0396]), tensor([40.0397]), tensor([40.0398]), tensor([40.0399])], [tensor([41.0390]), tensor([41.0391]), tensor([41.0392]), tensor([41.0393]), tensor([41.0394]), tensor([41.0395]), tensor([41.0396]), tensor([41.0397]), tensor([41.0398]), tensor([41.0399])], [tensor([42.0390]), tensor([42.0391]), tensor([42.0392]), tensor([42.0393]), tensor([42.0394]), tensor([42.0395]), tensor([42.0396]), tensor([42.0397]), tensor([42.0398]), tensor([42.0399])]]\n",
      "[[tensor([20.0960]), tensor([20.0961]), tensor([20.0962]), tensor([20.0963]), tensor([20.0964]), tensor([20.0965]), tensor([20.0966]), tensor([20.0967]), tensor([20.0968]), tensor([20.0969]), tensor([20.0970]), tensor([20.0971]), tensor([20.0972]), tensor([20.0973]), tensor([20.0974]), tensor([20.0975]), tensor([20.0976]), tensor([20.0977]), tensor([20.0978]), tensor([20.0979])], [tensor([21.0960]), tensor([21.0961]), tensor([21.0962]), tensor([21.0963]), tensor([21.0964]), tensor([21.0965]), tensor([21.0966]), tensor([21.0967]), tensor([21.0968]), tensor([21.0969]), tensor([21.0970]), tensor([21.0971]), tensor([21.0972]), tensor([21.0973]), tensor([21.0974]), tensor([21.0975]), tensor([21.0976]), tensor([21.0977]), tensor([21.0978]), tensor([21.0979])], [tensor([22.0960]), tensor([22.0961]), tensor([22.0962]), tensor([22.0963]), tensor([22.0964]), tensor([22.0965]), tensor([22.0966]), tensor([22.0967]), tensor([22.0968]), tensor([22.0969]), tensor([22.0970]), tensor([22.0971]), tensor([22.0972]), tensor([22.0973]), tensor([22.0974]), tensor([22.0975]), tensor([22.0976]), tensor([22.0977]), tensor([22.0978]), tensor([22.0979])]]\n",
      "[[tensor([20.0980]), tensor([20.0981]), tensor([20.0982]), tensor([20.0983]), tensor([20.0984]), tensor([20.0985]), tensor([20.0986]), tensor([20.0987]), tensor([20.0988]), tensor([20.0989]), tensor([20.0990]), tensor([20.0991]), tensor([20.0992]), tensor([20.0993]), tensor([20.0994]), tensor([20.0995]), tensor([20.0996]), tensor([20.0997]), tensor([20.0998]), tensor([20.0999])], [tensor([21.0980]), tensor([21.0981]), tensor([21.0982]), tensor([21.0983]), tensor([21.0984]), tensor([21.0985]), tensor([21.0986]), tensor([21.0987]), tensor([21.0988]), tensor([21.0989]), tensor([21.0990]), tensor([21.0991]), tensor([21.0992]), tensor([21.0993]), tensor([21.0994]), tensor([21.0995]), tensor([21.0996]), tensor([21.0997]), tensor([21.0998]), tensor([21.0999])], [tensor([22.0980]), tensor([22.0981]), tensor([22.0982]), tensor([22.0983]), tensor([22.0984]), tensor([22.0985]), tensor([22.0986]), tensor([22.0987]), tensor([22.0988]), tensor([22.0989]), tensor([22.0990]), tensor([22.0991]), tensor([22.0992]), tensor([22.0993]), tensor([22.0994]), tensor([22.0995]), tensor([22.0996]), tensor([22.0997]), tensor([22.0998]), tensor([22.0999])]]\n",
      "[[tensor([50.0180]), tensor([50.0181]), tensor([50.0182]), tensor([50.0183]), tensor([50.0184])], [tensor([51.0180]), tensor([51.0181]), tensor([51.0182]), tensor([51.0183]), tensor([51.0184])], [tensor([52.0180]), tensor([52.0181]), tensor([52.0182]), tensor([52.0183]), tensor([52.0184])]]\n",
      "[[tensor([50.0185]), tensor([50.0186]), tensor([50.0187]), tensor([50.0188]), tensor([50.0189])], [tensor([51.0185]), tensor([51.0186]), tensor([51.0187]), tensor([51.0188]), tensor([51.0189])], [tensor([52.0185]), tensor([52.0186]), tensor([52.0187]), tensor([52.0188]), tensor([52.0189])]]\n",
      "[[tensor([50.0190]), tensor([50.0191]), tensor([50.0192]), tensor([50.0193]), tensor([50.0194])], [tensor([51.0190]), tensor([51.0191]), tensor([51.0192]), tensor([51.0193]), tensor([51.0194])], [tensor([52.0190]), tensor([52.0191]), tensor([52.0192]), tensor([52.0193]), tensor([52.0194])]]\n",
      "[[tensor([50.0195]), tensor([50.0196]), tensor([50.0197]), tensor([50.0198]), tensor([50.0199])], [tensor([51.0195]), tensor([51.0196]), tensor([51.0197]), tensor([51.0198]), tensor([51.0199])], [tensor([52.0195]), tensor([52.0196]), tensor([52.0197]), tensor([52.0198]), tensor([52.0199])]]\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))\n",
    "for index,samples in enumerate(dataloader):\n",
    "    if index == 0 or index == len(dataloader)-1:\n",
    "        print(f\"index:{index}\")\n",
    "        for sample in samples:\n",
    "            print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dict = {\"taskA\":10,\"taskB\":20,\"taskC\":10}\n",
    "max_batch_size = 40\n",
    "assert max_batch_size == sum([batch_size_dict[key] for key in batch_size_dict.keys()]), \"batch_size_dictの合計がmax_batch_sizeと一致しません\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Callable, Any\n",
    "def each_task_collate_fn(batch):\n",
    "    #list[image,in_text,out_text]が入力される\n",
    "    sample_list = [[] for _ in range(len(batch[0]))]\n",
    "    for data in batch:\n",
    "        for i,sample in enumerate(data):\n",
    "            sample_list[i].append(sample)\n",
    "    return sample_list\n",
    "\n",
    "class MultiDataIterator():\n",
    "    def __init__(self,dataloader_list,min_step,multi_data_collate_fn=None) -> None:\n",
    "        self.iter_list = [iter(dataloader) for dataloader in dataloader_list]\n",
    "        self.min_step = min(min_step)\n",
    "        self.step = 0\n",
    "        self.multi_task_collate_fn = multi_data_collate_fn\n",
    "    def __next__(self):\n",
    "        if self.step == self.min_step:\n",
    "            raise StopIteration\n",
    "        \n",
    "        next_sample_list =  [next(iter) for iter in self.iter_list]#[taskA,taskB,taskC]\n",
    "        if type(next_sample_list[0]) == list:\n",
    "            next_sample = [[] for _ in range(len(next_sample_list[0]))]\n",
    "            for sample_list in next_sample_list:\n",
    "                for i,sample in enumerate(sample_list):\n",
    "                    next_sample[i].extend(sample) #[imageA,imageB,imageC],[in_textA,in_textB,in_textC],[out_textA,out_textB,out_textC]]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if self.multi_task_collate_fn is None:\n",
    "            next_sample = [torch.stack(sample) for sample in next_sample]\n",
    "        else:\n",
    "            next_sample = self.multi_task_collate_fn(next_sample)\n",
    "        self.step += 1\n",
    "        return next_sample\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "    \n",
    "class MultiDataLoader():\n",
    "    def __init__(self,dataset_dict:dict[str,DataLoader],batch_size_dict:dict[str,int],each_task_collate_fn_dict:dict[str,Callable]=None,multi_task_collate_fn=None,is_ddp=False,**dataloader_args) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            dataset_dict (dict[str,DataLoader]): {taskA:Dataset,taskB:Dataset,taskC:Dataset}のようなdict\n",
    "            batch_size_dict (_type_): ｛taskA:10,taskB:20,taskC:10｝のようなdict\n",
    "            each_task_collate_fn_dict (dict[str,function], optional): {taskA:collate_fnA,taskB:collate_fnB,task:C,collate_fnC}のようなdict. Defaults to None.\n",
    "            multi_task_collate_fn (_type_, optional): すべてのデータセットからのバッチを統合する関数 Defaults to None.\n",
    "            is_ddp (bool, optional): DDPか否か Defaults to False.\n",
    "        \"\"\"\n",
    "        if each_task_collate_fn_dict is None:\n",
    "            each_task_collate_fn_dict = {key:each_task_collate_fn for key in dataset_dict.keys()}\n",
    "        self.dataloader_list = [DataLoader(dataset_dict[key],batch_size_dict[key],collate_fn=each_task_collate_fn_dict[key],**dataloader_args) for key in dataset_dict.keys()]\n",
    "        self.step_list = [len(dataloader) for dataloader in self.dataloader_list]\n",
    "        self.min_step = min(self.step_list)\n",
    "        self.multi_task_collate_fn = multi_task_collate_fn\n",
    "    def __iter__(self):\n",
    "        return MultiDataIterator(self.dataloader_list,self.step_list,self.multi_task_collate_fn)\n",
    "    def __len__(self):\n",
    "        return self.min_step\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "index:1\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0229],\n",
      "        [40.0047],\n",
      "        [40.0062],\n",
      "        [40.0113],\n",
      "        [40.0358],\n",
      "        [40.0131],\n",
      "        [10.0057],\n",
      "        [40.0110],\n",
      "        [40.0420],\n",
      "        [40.0283],\n",
      "        [20.0115],\n",
      "        [20.0657],\n",
      "        [20.0967],\n",
      "        [20.1015],\n",
      "        [20.0224],\n",
      "        [20.0114],\n",
      "        [20.0372],\n",
      "        [20.0597],\n",
      "        [20.0783],\n",
      "        [20.0600],\n",
      "        [20.0447],\n",
      "        [20.0310],\n",
      "        [20.0623],\n",
      "        [20.0167],\n",
      "        [20.0365],\n",
      "        [20.0594],\n",
      "        [20.0280],\n",
      "        [20.0061],\n",
      "        [20.0575],\n",
      "        [20.0974],\n",
      "        [30.0001],\n",
      "        [30.0118],\n",
      "        [30.0073],\n",
      "        [30.0075],\n",
      "        [30.0262],\n",
      "        [30.0250],\n",
      "        [30.0217],\n",
      "        [50.0104],\n",
      "        [50.0158],\n",
      "        [50.0038]]), [tensor([41.0229]), tensor([41.0047]), tensor([41.0062]), tensor([41.0113]), tensor([41.0358]), tensor([41.0131]), tensor([11.0057]), tensor([41.0110]), tensor([41.0420]), tensor([41.0283]), tensor([21.0115]), tensor([21.0657]), tensor([21.0967]), tensor([21.1015]), tensor([21.0224]), tensor([21.0114]), tensor([21.0372]), tensor([21.0597]), tensor([21.0783]), tensor([21.0600]), tensor([21.0447]), tensor([21.0310]), tensor([21.0623]), tensor([21.0167]), tensor([21.0365]), tensor([21.0594]), tensor([21.0280]), tensor([21.0061]), tensor([21.0575]), tensor([21.0974]), tensor([31.0001]), tensor([31.0118]), tensor([31.0073]), tensor([31.0075]), tensor([31.0262]), tensor([31.0250]), tensor([31.0217]), tensor([51.0104]), tensor([51.0158]), tensor([51.0038])], [tensor([42.0229]), tensor([42.0047]), tensor([42.0062]), tensor([42.0113]), tensor([42.0358]), tensor([42.0131]), tensor([12.0057]), tensor([42.0110]), tensor([42.0420]), tensor([42.0283]), tensor([22.0115]), tensor([22.0657]), tensor([22.0967]), tensor([22.1015]), tensor([22.0224]), tensor([22.0114]), tensor([22.0372]), tensor([22.0597]), tensor([22.0783]), tensor([22.0600]), tensor([22.0447]), tensor([22.0310]), tensor([22.0623]), tensor([22.0167]), tensor([22.0365]), tensor([22.0594]), tensor([22.0280]), tensor([22.0061]), tensor([22.0575]), tensor([22.0974]), tensor([32.0001]), tensor([32.0118]), tensor([32.0073]), tensor([32.0075]), tensor([32.0262]), tensor([32.0250]), tensor([32.0217]), tensor([52.0104]), tensor([52.0158]), tensor([52.0038])])\n",
      "\n",
      "\n",
      "index:10\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0200],\n",
      "        [40.0278],\n",
      "        [40.0127],\n",
      "        [10.0080],\n",
      "        [40.0085],\n",
      "        [40.0263],\n",
      "        [40.0034],\n",
      "        [10.0028],\n",
      "        [40.0181],\n",
      "        [40.0245],\n",
      "        [20.0942],\n",
      "        [20.0200],\n",
      "        [20.0019],\n",
      "        [20.1042],\n",
      "        [20.0148],\n",
      "        [20.0204],\n",
      "        [20.0736],\n",
      "        [20.0940],\n",
      "        [20.0524],\n",
      "        [20.0668],\n",
      "        [20.0772],\n",
      "        [20.0764],\n",
      "        [20.0643],\n",
      "        [20.1019],\n",
      "        [20.0377],\n",
      "        [20.0052],\n",
      "        [20.1054],\n",
      "        [20.0421],\n",
      "        [20.0912],\n",
      "        [20.0065],\n",
      "        [30.0108],\n",
      "        [50.0077],\n",
      "        [50.0175],\n",
      "        [30.0147],\n",
      "        [50.0111],\n",
      "        [50.0025],\n",
      "        [30.0241],\n",
      "        [30.0287],\n",
      "        [50.0098],\n",
      "        [50.0072]]), [tensor([41.0200]), tensor([41.0278]), tensor([41.0127]), tensor([11.0080]), tensor([41.0085]), tensor([41.0263]), tensor([41.0034]), tensor([11.0028]), tensor([41.0181]), tensor([41.0245]), tensor([21.0942]), tensor([21.0200]), tensor([21.0019]), tensor([21.1042]), tensor([21.0148]), tensor([21.0204]), tensor([21.0736]), tensor([21.0940]), tensor([21.0524]), tensor([21.0668]), tensor([21.0772]), tensor([21.0764]), tensor([21.0643]), tensor([21.1019]), tensor([21.0377]), tensor([21.0052]), tensor([21.1054]), tensor([21.0421]), tensor([21.0912]), tensor([21.0065]), tensor([31.0108]), tensor([51.0077]), tensor([51.0175]), tensor([31.0147]), tensor([51.0111]), tensor([51.0025]), tensor([31.0241]), tensor([31.0287]), tensor([51.0098]), tensor([51.0072])], [tensor([42.0200]), tensor([42.0278]), tensor([42.0127]), tensor([12.0080]), tensor([42.0085]), tensor([42.0263]), tensor([42.0034]), tensor([12.0028]), tensor([42.0181]), tensor([42.0245]), tensor([22.0942]), tensor([22.0200]), tensor([22.0019]), tensor([22.1042]), tensor([22.0148]), tensor([22.0204]), tensor([22.0736]), tensor([22.0940]), tensor([22.0524]), tensor([22.0668]), tensor([22.0772]), tensor([22.0764]), tensor([22.0643]), tensor([22.1019]), tensor([22.0377]), tensor([22.0052]), tensor([22.1054]), tensor([22.0421]), tensor([22.0912]), tensor([22.0065]), tensor([32.0108]), tensor([52.0077]), tensor([52.0175]), tensor([32.0147]), tensor([52.0111]), tensor([52.0025]), tensor([32.0241]), tensor([32.0287]), tensor([52.0098]), tensor([52.0072])])\n",
      "\n",
      "\n",
      "index:30\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0271],\n",
      "        [40.0292],\n",
      "        [40.0136],\n",
      "        [40.0279],\n",
      "        [40.0193],\n",
      "        [40.0059],\n",
      "        [40.0130],\n",
      "        [10.0056],\n",
      "        [40.0107],\n",
      "        [10.0075],\n",
      "        [20.0236],\n",
      "        [20.0957],\n",
      "        [20.0639],\n",
      "        [20.0415],\n",
      "        [20.0506],\n",
      "        [20.0091],\n",
      "        [20.0542],\n",
      "        [20.0941],\n",
      "        [20.0851],\n",
      "        [20.0410],\n",
      "        [20.1056],\n",
      "        [20.0080],\n",
      "        [20.0146],\n",
      "        [20.0399],\n",
      "        [20.0446],\n",
      "        [20.0516],\n",
      "        [20.0239],\n",
      "        [20.0928],\n",
      "        [20.0048],\n",
      "        [20.0126],\n",
      "        [30.0021],\n",
      "        [30.0180],\n",
      "        [50.0110],\n",
      "        [30.0061],\n",
      "        [30.0087],\n",
      "        [50.0045],\n",
      "        [30.0292],\n",
      "        [30.0294],\n",
      "        [30.0190],\n",
      "        [30.0218]]), [tensor([41.0271]), tensor([41.0292]), tensor([41.0136]), tensor([41.0279]), tensor([41.0193]), tensor([41.0059]), tensor([41.0130]), tensor([11.0056]), tensor([41.0107]), tensor([11.0075]), tensor([21.0236]), tensor([21.0957]), tensor([21.0639]), tensor([21.0415]), tensor([21.0506]), tensor([21.0091]), tensor([21.0542]), tensor([21.0941]), tensor([21.0851]), tensor([21.0410]), tensor([21.1056]), tensor([21.0080]), tensor([21.0146]), tensor([21.0399]), tensor([21.0446]), tensor([21.0516]), tensor([21.0239]), tensor([21.0928]), tensor([21.0048]), tensor([21.0126]), tensor([31.0021]), tensor([31.0180]), tensor([51.0110]), tensor([31.0061]), tensor([31.0087]), tensor([51.0045]), tensor([31.0292]), tensor([31.0294]), tensor([31.0190]), tensor([31.0218])], [tensor([42.0271]), tensor([42.0292]), tensor([42.0136]), tensor([42.0279]), tensor([42.0193]), tensor([42.0059]), tensor([42.0130]), tensor([12.0056]), tensor([42.0107]), tensor([12.0075]), tensor([22.0236]), tensor([22.0957]), tensor([22.0639]), tensor([22.0415]), tensor([22.0506]), tensor([22.0091]), tensor([22.0542]), tensor([22.0941]), tensor([22.0851]), tensor([22.0410]), tensor([22.1056]), tensor([22.0080]), tensor([22.0146]), tensor([22.0399]), tensor([22.0446]), tensor([22.0516]), tensor([22.0239]), tensor([22.0928]), tensor([22.0048]), tensor([22.0126]), tensor([32.0021]), tensor([32.0180]), tensor([52.0110]), tensor([32.0061]), tensor([32.0087]), tensor([52.0045]), tensor([32.0292]), tensor([32.0294]), tensor([32.0190]), tensor([32.0218])])\n",
      "\n",
      "\n",
      "index:50\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0118],\n",
      "        [40.0001],\n",
      "        [40.0009],\n",
      "        [40.0436],\n",
      "        [10.0088],\n",
      "        [40.0312],\n",
      "        [40.0099],\n",
      "        [40.0335],\n",
      "        [40.0475],\n",
      "        [40.0199],\n",
      "        [20.0083],\n",
      "        [20.0069],\n",
      "        [20.0131],\n",
      "        [20.0775],\n",
      "        [20.0761],\n",
      "        [20.0212],\n",
      "        [20.0211],\n",
      "        [20.0118],\n",
      "        [20.0404],\n",
      "        [20.0670],\n",
      "        [20.0199],\n",
      "        [20.0102],\n",
      "        [20.0626],\n",
      "        [20.0347],\n",
      "        [20.0285],\n",
      "        [20.0631],\n",
      "        [20.1040],\n",
      "        [20.0828],\n",
      "        [20.0822],\n",
      "        [20.0358],\n",
      "        [50.0103],\n",
      "        [30.0247],\n",
      "        [50.0096],\n",
      "        [50.0016],\n",
      "        [30.0089],\n",
      "        [50.0020],\n",
      "        [30.0221],\n",
      "        [50.0084],\n",
      "        [30.0234],\n",
      "        [30.0192]]), [tensor([41.0118]), tensor([41.0001]), tensor([41.0009]), tensor([41.0436]), tensor([11.0088]), tensor([41.0312]), tensor([41.0099]), tensor([41.0335]), tensor([41.0475]), tensor([41.0199]), tensor([21.0083]), tensor([21.0069]), tensor([21.0131]), tensor([21.0775]), tensor([21.0761]), tensor([21.0212]), tensor([21.0211]), tensor([21.0118]), tensor([21.0404]), tensor([21.0670]), tensor([21.0199]), tensor([21.0102]), tensor([21.0626]), tensor([21.0347]), tensor([21.0285]), tensor([21.0631]), tensor([21.1040]), tensor([21.0828]), tensor([21.0822]), tensor([21.0358]), tensor([51.0103]), tensor([31.0247]), tensor([51.0096]), tensor([51.0016]), tensor([31.0089]), tensor([51.0020]), tensor([31.0221]), tensor([51.0084]), tensor([31.0234]), tensor([31.0192])], [tensor([42.0118]), tensor([42.0001]), tensor([42.0009]), tensor([42.0436]), tensor([12.0088]), tensor([42.0312]), tensor([42.0099]), tensor([42.0335]), tensor([42.0475]), tensor([42.0199]), tensor([22.0083]), tensor([22.0069]), tensor([22.0131]), tensor([22.0775]), tensor([22.0761]), tensor([22.0212]), tensor([22.0211]), tensor([22.0118]), tensor([22.0404]), tensor([22.0670]), tensor([22.0199]), tensor([22.0102]), tensor([22.0626]), tensor([22.0347]), tensor([22.0285]), tensor([22.0631]), tensor([22.1040]), tensor([22.0828]), tensor([22.0822]), tensor([22.0358]), tensor([52.0103]), tensor([32.0247]), tensor([52.0096]), tensor([52.0016]), tensor([32.0089]), tensor([52.0020]), tensor([32.0221]), tensor([52.0084]), tensor([32.0234]), tensor([32.0192])])\n",
      "\n",
      "\n",
      "index:1\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0416],\n",
      "        [40.0143],\n",
      "        [10.0042],\n",
      "        [40.0421],\n",
      "        [40.0376],\n",
      "        [10.0092],\n",
      "        [40.0134],\n",
      "        [40.0171],\n",
      "        [40.0203],\n",
      "        [40.0425],\n",
      "        [20.0909],\n",
      "        [20.0366],\n",
      "        [20.0458],\n",
      "        [20.0164],\n",
      "        [20.0861],\n",
      "        [20.0207],\n",
      "        [20.0720],\n",
      "        [20.0150],\n",
      "        [20.0772],\n",
      "        [20.1070],\n",
      "        [20.0682],\n",
      "        [20.0648],\n",
      "        [20.0191],\n",
      "        [20.0217],\n",
      "        [20.0007],\n",
      "        [20.0943],\n",
      "        [20.0123],\n",
      "        [20.0221],\n",
      "        [20.0740],\n",
      "        [20.0423],\n",
      "        [30.0128],\n",
      "        [30.0263],\n",
      "        [50.0020],\n",
      "        [30.0154],\n",
      "        [30.0157],\n",
      "        [30.0053],\n",
      "        [30.0168],\n",
      "        [30.0173],\n",
      "        [30.0044],\n",
      "        [30.0278]]), [tensor([41.0416]), tensor([41.0143]), tensor([11.0042]), tensor([41.0421]), tensor([41.0376]), tensor([11.0092]), tensor([41.0134]), tensor([41.0171]), tensor([41.0203]), tensor([41.0425]), tensor([21.0909]), tensor([21.0366]), tensor([21.0458]), tensor([21.0164]), tensor([21.0861]), tensor([21.0207]), tensor([21.0720]), tensor([21.0150]), tensor([21.0772]), tensor([21.1070]), tensor([21.0682]), tensor([21.0648]), tensor([21.0191]), tensor([21.0217]), tensor([21.0007]), tensor([21.0943]), tensor([21.0123]), tensor([21.0221]), tensor([21.0740]), tensor([21.0423]), tensor([31.0128]), tensor([31.0263]), tensor([51.0020]), tensor([31.0154]), tensor([31.0157]), tensor([31.0053]), tensor([31.0168]), tensor([31.0173]), tensor([31.0044]), tensor([31.0278])], [tensor([42.0416]), tensor([42.0143]), tensor([12.0042]), tensor([42.0421]), tensor([42.0376]), tensor([12.0092]), tensor([42.0134]), tensor([42.0171]), tensor([42.0203]), tensor([42.0425]), tensor([22.0909]), tensor([22.0366]), tensor([22.0458]), tensor([22.0164]), tensor([22.0861]), tensor([22.0207]), tensor([22.0720]), tensor([22.0150]), tensor([22.0772]), tensor([22.1070]), tensor([22.0682]), tensor([22.0648]), tensor([22.0191]), tensor([22.0217]), tensor([22.0007]), tensor([22.0943]), tensor([22.0123]), tensor([22.0221]), tensor([22.0740]), tensor([22.0423]), tensor([32.0128]), tensor([32.0263]), tensor([52.0020]), tensor([32.0154]), tensor([32.0157]), tensor([32.0053]), tensor([32.0168]), tensor([32.0173]), tensor([32.0044]), tensor([32.0278])])\n",
      "\n",
      "\n",
      "index:10\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0198],\n",
      "        [40.0455],\n",
      "        [40.0333],\n",
      "        [10.0009],\n",
      "        [40.0249],\n",
      "        [40.0457],\n",
      "        [40.0017],\n",
      "        [40.0231],\n",
      "        [40.0029],\n",
      "        [40.0326],\n",
      "        [20.0637],\n",
      "        [20.0468],\n",
      "        [20.0673],\n",
      "        [20.1067],\n",
      "        [20.0171],\n",
      "        [20.0426],\n",
      "        [20.0815],\n",
      "        [20.1043],\n",
      "        [20.0312],\n",
      "        [20.1011],\n",
      "        [20.1096],\n",
      "        [20.0176],\n",
      "        [20.1013],\n",
      "        [20.0632],\n",
      "        [20.0324],\n",
      "        [20.0510],\n",
      "        [20.0877],\n",
      "        [20.0202],\n",
      "        [20.0360],\n",
      "        [20.0608],\n",
      "        [50.0043],\n",
      "        [50.0098],\n",
      "        [50.0014],\n",
      "        [50.0004],\n",
      "        [50.0022],\n",
      "        [50.0156],\n",
      "        [30.0093],\n",
      "        [50.0072],\n",
      "        [50.0172],\n",
      "        [30.0136]]), [tensor([41.0198]), tensor([41.0455]), tensor([41.0333]), tensor([11.0009]), tensor([41.0249]), tensor([41.0457]), tensor([41.0017]), tensor([41.0231]), tensor([41.0029]), tensor([41.0326]), tensor([21.0637]), tensor([21.0468]), tensor([21.0673]), tensor([21.1067]), tensor([21.0171]), tensor([21.0426]), tensor([21.0815]), tensor([21.1043]), tensor([21.0312]), tensor([21.1011]), tensor([21.1096]), tensor([21.0176]), tensor([21.1013]), tensor([21.0632]), tensor([21.0324]), tensor([21.0510]), tensor([21.0877]), tensor([21.0202]), tensor([21.0360]), tensor([21.0608]), tensor([51.0043]), tensor([51.0098]), tensor([51.0014]), tensor([51.0004]), tensor([51.0022]), tensor([51.0156]), tensor([31.0093]), tensor([51.0072]), tensor([51.0172]), tensor([31.0136])], [tensor([42.0198]), tensor([42.0455]), tensor([42.0333]), tensor([12.0009]), tensor([42.0249]), tensor([42.0457]), tensor([42.0017]), tensor([42.0231]), tensor([42.0029]), tensor([42.0326]), tensor([22.0637]), tensor([22.0468]), tensor([22.0673]), tensor([22.1067]), tensor([22.0171]), tensor([22.0426]), tensor([22.0815]), tensor([22.1043]), tensor([22.0312]), tensor([22.1011]), tensor([22.1096]), tensor([22.0176]), tensor([22.1013]), tensor([22.0632]), tensor([22.0324]), tensor([22.0510]), tensor([22.0877]), tensor([22.0202]), tensor([22.0360]), tensor([22.0608]), tensor([52.0043]), tensor([52.0098]), tensor([52.0014]), tensor([52.0004]), tensor([52.0022]), tensor([52.0156]), tensor([32.0093]), tensor([52.0072]), tensor([52.0172]), tensor([32.0136])])\n",
      "\n",
      "\n",
      "index:30\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0309],\n",
      "        [10.0054],\n",
      "        [40.0208],\n",
      "        [40.0253],\n",
      "        [40.0363],\n",
      "        [40.0055],\n",
      "        [40.0184],\n",
      "        [40.0226],\n",
      "        [10.0038],\n",
      "        [40.0020],\n",
      "        [20.0042],\n",
      "        [20.0997],\n",
      "        [20.0495],\n",
      "        [20.0314],\n",
      "        [20.0626],\n",
      "        [20.0492],\n",
      "        [20.0721],\n",
      "        [20.0019],\n",
      "        [20.0718],\n",
      "        [20.0225],\n",
      "        [20.1053],\n",
      "        [20.0108],\n",
      "        [20.0239],\n",
      "        [20.0778],\n",
      "        [20.0433],\n",
      "        [20.0671],\n",
      "        [20.0124],\n",
      "        [20.0526],\n",
      "        [20.0195],\n",
      "        [20.0541],\n",
      "        [30.0167],\n",
      "        [50.0132],\n",
      "        [30.0218],\n",
      "        [30.0152],\n",
      "        [50.0089],\n",
      "        [50.0154],\n",
      "        [30.0224],\n",
      "        [30.0003],\n",
      "        [30.0189],\n",
      "        [30.0090]]), [tensor([41.0309]), tensor([11.0054]), tensor([41.0208]), tensor([41.0253]), tensor([41.0363]), tensor([41.0055]), tensor([41.0184]), tensor([41.0226]), tensor([11.0038]), tensor([41.0020]), tensor([21.0042]), tensor([21.0997]), tensor([21.0495]), tensor([21.0314]), tensor([21.0626]), tensor([21.0492]), tensor([21.0721]), tensor([21.0019]), tensor([21.0718]), tensor([21.0225]), tensor([21.1053]), tensor([21.0108]), tensor([21.0239]), tensor([21.0778]), tensor([21.0433]), tensor([21.0671]), tensor([21.0124]), tensor([21.0526]), tensor([21.0195]), tensor([21.0541]), tensor([31.0167]), tensor([51.0132]), tensor([31.0218]), tensor([31.0152]), tensor([51.0089]), tensor([51.0154]), tensor([31.0224]), tensor([31.0003]), tensor([31.0189]), tensor([31.0090])], [tensor([42.0309]), tensor([12.0054]), tensor([42.0208]), tensor([42.0253]), tensor([42.0363]), tensor([42.0055]), tensor([42.0184]), tensor([42.0226]), tensor([12.0038]), tensor([42.0020]), tensor([22.0042]), tensor([22.0997]), tensor([22.0495]), tensor([22.0314]), tensor([22.0626]), tensor([22.0492]), tensor([22.0721]), tensor([22.0019]), tensor([22.0718]), tensor([22.0225]), tensor([22.1053]), tensor([22.0108]), tensor([22.0239]), tensor([22.0778]), tensor([22.0433]), tensor([22.0671]), tensor([22.0124]), tensor([22.0526]), tensor([22.0195]), tensor([22.0541]), tensor([32.0167]), tensor([52.0132]), tensor([32.0218]), tensor([32.0152]), tensor([52.0089]), tensor([52.0154]), tensor([32.0224]), tensor([32.0003]), tensor([32.0189]), tensor([32.0090])])\n",
      "\n",
      "\n",
      "index:50\n",
      "[40, 40, 40]\n",
      "(tensor([[40.0086],\n",
      "        [40.0383],\n",
      "        [40.0387],\n",
      "        [40.0242],\n",
      "        [40.0480],\n",
      "        [40.0494],\n",
      "        [40.0445],\n",
      "        [10.0023],\n",
      "        [40.0167],\n",
      "        [40.0459],\n",
      "        [20.0420],\n",
      "        [20.0585],\n",
      "        [20.0818],\n",
      "        [20.0502],\n",
      "        [20.0306],\n",
      "        [20.0554],\n",
      "        [20.0868],\n",
      "        [20.0112],\n",
      "        [20.0310],\n",
      "        [20.0037],\n",
      "        [20.1007],\n",
      "        [20.0529],\n",
      "        [20.0757],\n",
      "        [20.0946],\n",
      "        [20.0013],\n",
      "        [20.0146],\n",
      "        [20.0354],\n",
      "        [20.0391],\n",
      "        [20.0148],\n",
      "        [20.0357],\n",
      "        [50.0151],\n",
      "        [30.0240],\n",
      "        [30.0149],\n",
      "        [50.0041],\n",
      "        [50.0077],\n",
      "        [30.0205],\n",
      "        [30.0211],\n",
      "        [30.0248],\n",
      "        [50.0136],\n",
      "        [30.0139]]), [tensor([41.0086]), tensor([41.0383]), tensor([41.0387]), tensor([41.0242]), tensor([41.0480]), tensor([41.0494]), tensor([41.0445]), tensor([11.0023]), tensor([41.0167]), tensor([41.0459]), tensor([21.0420]), tensor([21.0585]), tensor([21.0818]), tensor([21.0502]), tensor([21.0306]), tensor([21.0554]), tensor([21.0868]), tensor([21.0112]), tensor([21.0310]), tensor([21.0037]), tensor([21.1007]), tensor([21.0529]), tensor([21.0757]), tensor([21.0946]), tensor([21.0013]), tensor([21.0146]), tensor([21.0354]), tensor([21.0391]), tensor([21.0148]), tensor([21.0357]), tensor([51.0151]), tensor([31.0240]), tensor([31.0149]), tensor([51.0041]), tensor([51.0077]), tensor([31.0205]), tensor([31.0211]), tensor([31.0248]), tensor([51.0136]), tensor([31.0139])], [tensor([42.0086]), tensor([42.0383]), tensor([42.0387]), tensor([42.0242]), tensor([42.0480]), tensor([42.0494]), tensor([42.0445]), tensor([12.0023]), tensor([42.0167]), tensor([42.0459]), tensor([22.0420]), tensor([22.0585]), tensor([22.0818]), tensor([22.0502]), tensor([22.0306]), tensor([22.0554]), tensor([22.0868]), tensor([22.0112]), tensor([22.0310]), tensor([22.0037]), tensor([22.1007]), tensor([22.0529]), tensor([22.0757]), tensor([22.0946]), tensor([22.0013]), tensor([22.0146]), tensor([22.0354]), tensor([22.0391]), tensor([22.0148]), tensor([22.0357]), tensor([52.0151]), tensor([32.0240]), tensor([32.0149]), tensor([52.0041]), tensor([52.0077]), tensor([32.0205]), tensor([32.0211]), tensor([32.0248]), tensor([52.0136]), tensor([32.0139])])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def multi_task_collate_fn(sample):\n",
    "    #[[image_list],[in_text_list],[out_text_list]]が入力される\n",
    "    \n",
    "    image_list = sample[0]\n",
    "    in_text_list = sample[1]\n",
    "    out_text_list = sample[2]\n",
    "    return torch.stack(image_list),in_text_list,out_text_list\n",
    "multi_dataloader = MultiDataLoader(dataset_dict,batch_size_dict,shuffle=True,drop_last=True,multi_task_collate_fn=multi_task_collate_fn)\n",
    "print(len(multi_dataloader))\n",
    "print_slices = [1,10,30,50]\n",
    "epoch = 2\n",
    "for _ in range(epoch):\n",
    "    for index,data in enumerate(multi_dataloader):\n",
    "        if index+1 in print_slices:\n",
    "            print(f\"index:{index+1}\")\n",
    "            print([len(data[i]) for i in range(len(data))])\n",
    "            print(data)\n",
    "            print(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "tensor([[2, 1, 2, 2, 2, 2, 0, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 1, 1, 2, 1, 2, 1],\n",
      "        [1, 1, 2, 0, 2, 2, 0, 0, 1, 1],\n",
      "        [0, 1, 2, 0, 1, 1, 0, 0, 1, 2],\n",
      "        [2, 2, 2, 0, 2, 1, 1, 2, 1, 0]])\n",
      "torch.Size([5, 11])\n",
      "tensor([[2, 1, 2, 2, 2, 2, 0, 0, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 0],\n",
      "        [1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 0],\n",
      "        [0, 1, 2, 0, 1, 1, 0, 0, 1, 2, 0],\n",
      "        [2, 2, 2, 0, 2, 1, 1, 2, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "source = torch.randint(0,3,(5,10))\n",
    "print(source.shape)\n",
    "print(source)\n",
    "# now we expand to size (7, 11) by appending a row of 0s at pos 0 and pos 6, \n",
    "# and a column of 0s at pos 10\n",
    "result = F.pad(input=source, pad=(0, 1, 0, 0), mode='constant', value=0)\n",
    "print(result.shape)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 3, 3, 2, 3, 6, 7, 6, 6, 7],\n",
      "        [8, 7, 1, 3, 8, 2, 1, 3, 2, 2],\n",
      "        [6, 2, 6, 3, 1, 3, 3, 6, 6, 7],\n",
      "        [8, 1, 6, 6, 6, 8, 5, 8, 5, 2],\n",
      "        [7, 8, 4, 7, 1, 3, 3, 8, 4, 5]])\n",
      "tensor([[3, 3, 6, 8, 4, 6, 2, 4, 2, 5, 2, 7, 1, 6, 2, 5, 3, 2, 3, 1],\n",
      "        [7, 8, 7, 1, 3, 7, 3, 5, 3, 5, 8, 7, 5, 5, 5, 5, 5, 7, 3, 6],\n",
      "        [6, 5, 5, 7, 7, 5, 7, 1, 3, 5, 8, 6, 1, 8, 3, 7, 5, 4, 2, 4],\n",
      "        [2, 4, 5, 7, 5, 7, 5, 4, 8, 8, 4, 3, 4, 8, 3, 1, 5, 8, 3, 1],\n",
      "        [8, 4, 2, 1, 3, 8, 8, 4, 3, 8, 6, 7, 1, 3, 6, 5, 8, 5, 7, 8],\n",
      "        [7, 8, 5, 5, 8, 8, 4, 2, 8, 5, 5, 5, 5, 3, 1, 3, 6, 8, 4, 7],\n",
      "        [4, 3, 2, 4, 4, 7, 2, 1, 5, 3, 4, 4, 4, 2, 3, 6, 3, 5, 6, 2],\n",
      "        [8, 6, 5, 3, 6, 5, 3, 5, 5, 3, 4, 3, 1, 4, 7, 7, 1, 3, 2, 6],\n",
      "        [5, 1, 3, 2, 6, 1, 4, 8, 7, 6, 7, 2, 1, 6, 4, 3, 7, 2, 7, 2],\n",
      "        [6, 7, 5, 1, 1, 4, 7, 3, 4, 8, 3, 8, 6, 6, 4, 7, 4, 1, 3, 1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb セル 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707541363030302d3035227d/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pad_value \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707541363030302d3035227d/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrnn\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequence\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707541363030302d3035227d/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m source1 \u001b[39m=\u001b[39m pad_sequence([source1,source2],batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,padding_value\u001b[39m=\u001b[39;49mpad_value)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707541363030302d3035227d/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(source1\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267707541363030302d3035227d/home/omote/WorkSpace/KLab_list/KLab_MultiModalModel/multi_task_train/make_data.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m source1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39msource1, pad\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, max_length\u001b[39m-\u001b[39msource1\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, value\u001b[39m=\u001b[39mpad_value)\n",
      "File \u001b[0;32m/opt/pipenv/KLab_MultiModalModel-XfRlqCgI/lib/python3.10/site-packages/torch/nn/utils/rnn.py:400\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    396\u001b[0m         sequences \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m)\n\u001b[1;32m    398\u001b[0m \u001b[39m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mpad_sequence(sequences, batch_first, padding_value)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "source1 = torch.randint(1,9,(5,10))\n",
    "source2 = torch.randint(1,9,(10,20))\n",
    "print(source1)\n",
    "print(source2)\n",
    "max_length = max(source1.shape[-1],source2.shape[-1])\n",
    "pad_value = 0\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# source1 = pad_sequence([source1,source2],batch_first=True,padding_value=pad_value)\n",
    "# print(source1.shape)\n",
    "source1 = F.pad(input=source1, pad=(0, max_length-source1.shape[-1]), mode='constant', value=pad_value)\n",
    "source2 = F.pad(input=source2, pad=(0, max_length-source2.shape[-1]), mode='constant', value=pad_value)\n",
    "source = torch.vstack([source1,source2])\n",
    "print(\"source\")\n",
    "print(source.shape)\n",
    "print(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(self, batch):\n",
    "    # バッチ内のテンソルをパッドする\n",
    "    src_images, tgt_images, src_texts, tgt_texts = [], [], [], []\n",
    "    for src_image, tgt_image, src_text, tgt_text in batch:\n",
    "        src_images.append(src_image)\n",
    "        tgt_images.append(tgt_image)\n",
    "        src_texts.append(src_text)\n",
    "        tgt_texts.append(tgt_text)\n",
    "\n",
    "    src_images = torch.stack(src_images)\n",
    "    tgt_images = torch.stack(tgt_images)\n",
    "    src_texts = pad_sequence(src_texts, batch_first=True, padding_value=self.src_tokenizer.pad_token_id)\n",
    "    tgt_texts = pad_sequence(tgt_texts, batch_first=True, padding_value=self.tgt_tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = MyDataset(\"./dataset_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10.]), tensor([11.]), tensor([12.])]\n",
      "[tensor([10.0001]), tensor([11.0001]), tensor([12.0001])]\n",
      "[tensor([10.0002]), tensor([11.0002]), tensor([12.0002])]\n",
      "[tensor([10.0003]), tensor([11.0003]), tensor([12.0003])]\n",
      "[tensor([10.0004]), tensor([11.0004]), tensor([12.0004])]\n",
      "[tensor([10.0005]), tensor([11.0005]), tensor([12.0005])]\n",
      "[tensor([10.0006]), tensor([11.0006]), tensor([12.0006])]\n",
      "[tensor([10.0007]), tensor([11.0007]), tensor([12.0007])]\n",
      "[tensor([10.0008]), tensor([11.0008]), tensor([12.0008])]\n",
      "[tensor([10.0009]), tensor([11.0009]), tensor([12.0009])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset_1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[tensor([[10.0000],\n",
      "        [10.0001],\n",
      "        [10.0002],\n",
      "        [10.0003],\n",
      "        [10.0004],\n",
      "        [10.0005],\n",
      "        [10.0006],\n",
      "        [10.0007],\n",
      "        [10.0008],\n",
      "        [10.0009]]), tensor([[11.0000],\n",
      "        [11.0001],\n",
      "        [11.0002],\n",
      "        [11.0003],\n",
      "        [11.0004],\n",
      "        [11.0005],\n",
      "        [11.0006],\n",
      "        [11.0007],\n",
      "        [11.0008],\n",
      "        [11.0009]]), tensor([[12.0000],\n",
      "        [12.0001],\n",
      "        [12.0002],\n",
      "        [12.0003],\n",
      "        [12.0004],\n",
      "        [12.0005],\n",
      "        [12.0006],\n",
      "        [12.0007],\n",
      "        [12.0008],\n",
      "        [12.0009]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset_1, batch_size=10, shuffle=False)\n",
    "dataloader_iter = iter(dataloader)\n",
    "print(next(dataloader_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))\n",
    "print(len(iter(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex_module import ExModel\n",
    "model = ExModel(None)\n",
    "data = next(dataloader_iter)\n",
    "out = model(data[0], data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data1 = [[1],[2],[3]]\n",
    "data2 = [[4],[5],[6],[7]]\n",
    "print(torch.cat([torch.tensor(data1), torch.tensor(data2)],dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ChainDataset\n",
    "from ex_module import MyDataset,MyChainDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = MyDataset(\"./dataset_1.csv\")\n",
    "dataset_2 = MyDataset(\"./dataset_2.csv\")\n",
    "dataset_3 = MyDataset(\"./dataset_3.csv\")\n",
    "\n",
    "dataset = MyChainDataset([dataset_1, dataset_2, dataset_3],[[0,1],[1,2],[2,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True,num_workers=4,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[21.0079],\n",
      "        [21.0603],\n",
      "        [21.0834],\n",
      "        [21.0860]]), tensor([[22.0079],\n",
      "        [22.0603],\n",
      "        [22.0834],\n",
      "        [22.0860]])]\n",
      "[tensor([[10.0053],\n",
      "        [21.0394],\n",
      "        [21.0858],\n",
      "        [21.0271]]), tensor([[11.0053],\n",
      "        [22.0394],\n",
      "        [22.0858],\n",
      "        [22.0271]])]\n",
      "[tensor([[32.0271],\n",
      "        [21.0072],\n",
      "        [21.0586],\n",
      "        [32.0232]]), tensor([[30.0271],\n",
      "        [22.0072],\n",
      "        [22.0586],\n",
      "        [30.0232]])]\n",
      "[tensor([[21.0893],\n",
      "        [21.0944],\n",
      "        [21.0180],\n",
      "        [21.0756]]), tensor([[22.0893],\n",
      "        [22.0944],\n",
      "        [22.0180],\n",
      "        [22.0756]])]\n",
      "[tensor([[32.0252],\n",
      "        [21.0284],\n",
      "        [21.0052],\n",
      "        [32.0263]]), tensor([[30.0252],\n",
      "        [22.0284],\n",
      "        [22.0052],\n",
      "        [30.0263]])]\n",
      "[tensor([[21.0931],\n",
      "        [21.0924],\n",
      "        [21.0279],\n",
      "        [21.0547]]), tensor([[22.0931],\n",
      "        [22.0924],\n",
      "        [22.0279],\n",
      "        [22.0547]])]\n",
      "[tensor([[21.0353],\n",
      "        [21.0164],\n",
      "        [21.1006],\n",
      "        [21.0930]]), tensor([[22.0353],\n",
      "        [22.0164],\n",
      "        [22.1006],\n",
      "        [22.0930]])]\n",
      "[tensor([[32.0037],\n",
      "        [21.0885],\n",
      "        [32.0190],\n",
      "        [32.0133]]), tensor([[30.0037],\n",
      "        [22.0885],\n",
      "        [30.0190],\n",
      "        [30.0133]])]\n",
      "[tensor([[32.0182],\n",
      "        [10.0061],\n",
      "        [21.1046],\n",
      "        [10.0029]]), tensor([[30.0182],\n",
      "        [11.0061],\n",
      "        [22.1046],\n",
      "        [11.0029]])]\n",
      "[tensor([[21.0898],\n",
      "        [21.0842],\n",
      "        [32.0256],\n",
      "        [21.0272]]), tensor([[22.0898],\n",
      "        [22.0842],\n",
      "        [30.0256],\n",
      "        [22.0272]])]\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "for i in range(10):\n",
    "    print(next(data_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset[\u001b[39m1500\u001b[39;49m]\n",
      "File \u001b[0;32m~/WorkSpace/KLab_MultiModalModel/multi_task_train/ex_module.py:79\u001b[0m, in \u001b[0;36mMyChainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         idx \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset[1500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KLab_MultiModalModel-Zh2ecsZR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
