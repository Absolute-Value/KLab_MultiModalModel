+ module load cuda
++ /usr/bin/modulecmd bash load cuda
+ eval CPATH=/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/include:/home/center/opt/x86_64/cores/cuda/12.0.1/include ';export' 'CPATH;CUDA_HOME=/home/center/opt/x86_64/cores/cuda/12.0.1' ';export' 'CUDA_HOME;CUDA_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1' ';export' 'CUDA_PATH;FLOW_CUDA_NAME=cuda' ';export' 'FLOW_CUDA_NAME;FLOW_CUDA_VER=12.0.1' ';export' 'FLOW_CUDA_VER;LD_LIBRARY_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/targets/x86_64-linux/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/lib64:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64' ';export' 'LD_LIBRARY_PATH;LIBRARY_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/lib64' ';export' 'LIBRARY_PATH;LOADEDMODULES=cuda/12.0.1' ';export' 'LOADEDMODULES;MANPATH=/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man' ';export' 'MANPATH;MODULEPATH=/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/core:/center/local/app/x86/hpci/modulefiles' ';export' 'MODULEPATH;PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin' ';export' 'PATH;_LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1' ';export' '_LMFILES_;'
++ CPATH=/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/include:/home/center/opt/x86_64/cores/cuda/12.0.1/include
++ export CPATH
++ CUDA_HOME=/home/center/opt/x86_64/cores/cuda/12.0.1
++ export CUDA_HOME
++ CUDA_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1
++ export CUDA_PATH
++ FLOW_CUDA_NAME=cuda
++ export FLOW_CUDA_NAME
++ FLOW_CUDA_VER=12.0.1
++ export FLOW_CUDA_VER
++ LD_LIBRARY_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/targets/x86_64-linux/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/lib64:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64
++ export LD_LIBRARY_PATH
++ LIBRARY_PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/lib64
++ export LIBRARY_PATH
++ LOADEDMODULES=cuda/12.0.1
++ export LOADEDMODULES
++ MANPATH=/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man
++ export MANPATH
++ MODULEPATH=/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/core:/center/local/app/x86/hpci/modulefiles
++ export MODULEPATH
++ PATH=/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin
++ export PATH
++ _LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1
++ export _LMFILES_
+ module load openmpi_cuda
++ /usr/bin/modulecmd bash load openmpi_cuda
+ eval CPATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/include:/home/center/opt/x86_64/cores/cuda/12.0.1/include ';export' 'CPATH;INCLUDE_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include' ';export' 'INCLUDE_PATH;LD_LIBRARY_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/targets/x86_64-linux/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/lib64:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64' ';export' 'LD_LIBRARY_PATH;LIBRARY_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64' ';export' 'LIBRARY_PATH;LOADEDMODULES=cuda/12.0.1:openmpi_cuda/4.1.5' ';export' 'LOADEDMODULES;MANPATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/share/man:/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man' ';export' 'MANPATH;OMPI_MCA_btl=\^openib' ';export' 'OMPI_MCA_btl;OMPI_MCA_plm_rsh_agent=/bin/pjrsh' ';export' 'OMPI_MCA_plm_rsh_agent;OPENMPI_CUDA_DIR=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5' ';export' 'OPENMPI_CUDA_DIR;OPENMPI_CUDA_INC=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include' ';export' 'OPENMPI_CUDA_INC;OPENMPI_CUDA_LIB=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib' ';export' 'OPENMPI_CUDA_LIB;PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/bin:/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin' ';export' 'PATH;PKG_CONFIG_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib/pkgconfig' ';export' 'PKG_CONFIG_PATH;_LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1/openmpi_cuda/4.1.5' ';export' '_LMFILES_;'
++ CPATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/include:/home/center/opt/x86_64/cores/cuda/12.0.1/include
++ export CPATH
++ INCLUDE_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include
++ export INCLUDE_PATH
++ LD_LIBRARY_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/targets/x86_64-linux/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/extras/CUPTI/lib64:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64
++ export LD_LIBRARY_PATH
++ LIBRARY_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib:/home/center/opt/x86_64/cores/cuda/12.0.1/lib64
++ export LIBRARY_PATH
++ LOADEDMODULES=cuda/12.0.1:openmpi_cuda/4.1.5
++ export LOADEDMODULES
++ MANPATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/share/man:/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man
++ export MANPATH
++ OMPI_MCA_btl='^openib'
++ export OMPI_MCA_btl
++ OMPI_MCA_plm_rsh_agent=/bin/pjrsh
++ export OMPI_MCA_plm_rsh_agent
++ OPENMPI_CUDA_DIR=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5
++ export OPENMPI_CUDA_DIR
++ OPENMPI_CUDA_INC=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/include
++ export OPENMPI_CUDA_INC
++ OPENMPI_CUDA_LIB=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib
++ export OPENMPI_CUDA_LIB
++ PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/bin:/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin
++ export PATH
++ PKG_CONFIG_PATH=/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/lib/pkgconfig
++ export PKG_CONFIG_PATH
++ _LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1/openmpi_cuda/4.1.5
++ export _LMFILES_
+ module load singularity
++ /usr/bin/modulecmd bash load singularity
+ eval LOADEDMODULES=cuda/12.0.1:openmpi_cuda/4.1.5:singularity/3.10.5 ';export' 'LOADEDMODULES;MANPATH=/home/center/opt/x86_64/apps/singularity/3.10.5/share/man:/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/share/man:/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man' ';export' 'MANPATH;PATH=/home/center/opt/x86_64/apps/singularity/3.10.5/bin:/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/bin:/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin' ';export' 'PATH;SINGULARITY_DIR=/home/center/opt/x86_64/apps/singularity/3.10.5' ';export' 'SINGULARITY_DIR;_LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1/openmpi_cuda/4.1.5:/home/center/opt/x86_64/modulefiles/CX/core/singularity/3.10.5' ';export' '_LMFILES_;'
++ LOADEDMODULES=cuda/12.0.1:openmpi_cuda/4.1.5:singularity/3.10.5
++ export LOADEDMODULES
++ MANPATH=/home/center/opt/x86_64/apps/singularity/3.10.5/share/man:/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/share/man:/center/local/app/x86/nano/share/man:/usr/local/share/man:/usr/share/man
++ export MANPATH
++ PATH=/home/center/opt/x86_64/apps/singularity/3.10.5/bin:/home/center/opt/x86_64/apps/cuda/12.0.1/openmpi_cuda/4.1.5/bin:/home/center/opt/x86_64/cores/cuda/12.0.1/bin:/center/local/app/x86/nano/bin:/home/center/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/w49009a/.local/bin:/home/w49009a/bin
++ export PATH
++ SINGULARITY_DIR=/home/center/opt/x86_64/apps/singularity/3.10.5
++ export SINGULARITY_DIR
++ _LMFILES_=/home/center/opt/x86_64/modulefiles/CX/core/cuda/12.0.1:/home/center/opt/x86_64/modulefiles/CX/compiler/cuda/12.0.1/openmpi_cuda/4.1.5:/home/center/opt/x86_64/modulefiles/CX/core/singularity/3.10.5
++ export _LMFILES_
+ mpirun -n 1 -machinefile /home/w49009a/omote/KLab_MultiModalModel/multi_task_train/.d0001285308_nodeinfo -report-bindings -map-by ppr:2:socket singularity exec --nv /home/w49009a/pytorch_omote.sif bash /home/w49009a/omote/KLab_MultiModalModel/multi_task_train/test_each_node_task_train.sh
[cx052:00065] MCW rank 0 bound to socket 0[core 0[hwt 0]]: [B/././././././././././././././././././.][./././././././././././././././././././.]
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.60.13
rm: cannot remove '/usr/local/cuda/compat/lib': Read-only file system
rm: cannot remove '/usr/local/cuda/compat/lib': Read-only file system
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:27971 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to ?UNKNOWN? (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to ?UNKNOWN? (errno: 97 - Address family not supported by protocol).
2023-09-09 09:29:38,715: Options: {'image_model_name': 'microsoft/swinv2-base-patch4-window8-256', 'image_model_train': False, 'language_model_name': 'google/flan-t5-base', 'ffn': False, 'transformer_d_model': 512, 'transformer_d_ff': 2048, 'transformer_d_kv': 64, 'transformer_num_heads': 2, 'transformer_num_layers': 8, 'transformer_num_decoder_layers': 8, 'image_vocab_size': 16384, 'loc_vocab_size': 1000, 'vae_ckpt_path': 'checkpoints/vqgan.pt', 'max_source_length': 256, 'max_target_length': 256, 'pretrain': False, 'seed': 999, 'loss': 'FocalLoss', 'lr': 0.01, 'optimizer': 'AdamW', 'lr_scheduler': '', 'batch_size': 64, 'accumulation_steps': 1, 'num_epochs': 2, 'num_steps': None, 'warmup_steps': None, 'save_interval': None, 'datasets': ['imagenet', 'sun397'], 'root_dir': '/user/data/', 'result_dir': 'results/multi_task_train/', 'gpu_nums': 1}
2023-09-09 09:29:38,715: make_logger
/home/w49009a/omote/KLab_MultiModalModel/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2023-09-09 09:29:42,274: rank:0 || start training
2023-09-09 09:29:42,274: min_step: 22, max_step: 27
2023-09-09 09:29:44,260: epoch:1 step:1 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:44,326: epoch:1 step:1 rank:0 || image:[tensor([10.0000, 10.0001], device='cuda:0'), tensor([20.0000, 20.0001], device='cuda:0')] || in_text:[tensor([11.0000, 11.0001], device='cuda:0'), tensor([21.0000, 21.0001], device='cuda:0')] || out_text:[tensor([12.0000, 12.0001], device='cuda:0'), tensor([22.0000, 22.0001], device='cuda:0')]
2023-09-09 09:29:46,322: epoch:1 step:2 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,326: epoch:1 step:2 rank:0 || image:[tensor([10.0015, 10.0016], device='cuda:0'), tensor([20.0050, 20.0051], device='cuda:0')] || in_text:[tensor([11.0015, 11.0016], device='cuda:0'), tensor([21.0050, 21.0051], device='cuda:0')] || out_text:[tensor([12.0015, 12.0016], device='cuda:0'), tensor([22.0050, 22.0051], device='cuda:0')]
2023-09-09 09:29:46,345: epoch:1 step:3 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,348: epoch:1 step:3 rank:0 || image:[tensor([10.0030, 10.0031], device='cuda:0'), tensor([20.0100, 20.0101], device='cuda:0')] || in_text:[tensor([11.0030, 11.0031], device='cuda:0'), tensor([21.0100, 21.0101], device='cuda:0')] || out_text:[tensor([12.0030, 12.0031], device='cuda:0'), tensor([22.0100, 22.0101], device='cuda:0')]
2023-09-09 09:29:46,355: epoch:1 step:4 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,357: epoch:1 step:4 rank:0 || image:[tensor([10.0045, 10.0046], device='cuda:0'), tensor([20.0150, 20.0151], device='cuda:0')] || in_text:[tensor([11.0045, 11.0046], device='cuda:0'), tensor([21.0150, 21.0151], device='cuda:0')] || out_text:[tensor([12.0045, 12.0046], device='cuda:0'), tensor([22.0150, 22.0151], device='cuda:0')]
2023-09-09 09:29:46,362: epoch:1 step:5 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,365: epoch:1 step:5 rank:0 || image:[tensor([10.0060, 10.0061], device='cuda:0'), tensor([20.0200, 20.0201], device='cuda:0')] || in_text:[tensor([11.0060, 11.0061], device='cuda:0'), tensor([21.0200, 21.0201], device='cuda:0')] || out_text:[tensor([12.0060, 12.0061], device='cuda:0'), tensor([22.0200, 22.0201], device='cuda:0')]
2023-09-09 09:29:46,369: epoch:1 step:6 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,372: epoch:1 step:6 rank:0 || image:[tensor([10.0075, 10.0076], device='cuda:0'), tensor([20.0250, 20.0251], device='cuda:0')] || in_text:[tensor([11.0075, 11.0076], device='cuda:0'), tensor([21.0250, 21.0251], device='cuda:0')] || out_text:[tensor([12.0075, 12.0076], device='cuda:0'), tensor([22.0250, 22.0251], device='cuda:0')]
2023-09-09 09:29:46,377: epoch:1 step:7 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,379: epoch:1 step:7 rank:0 || image:[tensor([10.0090, 10.0091], device='cuda:0'), tensor([20.0300, 20.0301], device='cuda:0')] || in_text:[tensor([11.0090, 11.0091], device='cuda:0'), tensor([21.0300, 21.0301], device='cuda:0')] || out_text:[tensor([12.0090, 12.0091], device='cuda:0'), tensor([22.0300, 22.0301], device='cuda:0')]
2023-09-09 09:29:46,384: epoch:1 step:8 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,386: epoch:1 step:8 rank:0 || image:[tensor([30.0005, 30.0006], device='cuda:0'), tensor([20.0350, 20.0351], device='cuda:0')] || in_text:[tensor([31.0005, 31.0006], device='cuda:0'), tensor([21.0350, 21.0351], device='cuda:0')] || out_text:[tensor([32.0005, 32.0006], device='cuda:0'), tensor([22.0350, 22.0351], device='cuda:0')]
2023-09-09 09:29:46,394: epoch:1 step:9 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,397: epoch:1 step:9 rank:0 || image:[tensor([30.0020, 30.0021], device='cuda:0'), tensor([20.0400, 20.0401], device='cuda:0')] || in_text:[tensor([31.0020, 31.0021], device='cuda:0'), tensor([21.0400, 21.0401], device='cuda:0')] || out_text:[tensor([32.0020, 32.0021], device='cuda:0'), tensor([22.0400, 22.0401], device='cuda:0')]
2023-09-09 09:29:46,401: epoch:1 step:10 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,404: epoch:1 step:10 rank:0 || image:[tensor([30.0035, 30.0036], device='cuda:0'), tensor([20.0450, 20.0451], device='cuda:0')] || in_text:[tensor([31.0035, 31.0036], device='cuda:0'), tensor([21.0450, 21.0451], device='cuda:0')] || out_text:[tensor([32.0035, 32.0036], device='cuda:0'), tensor([22.0450, 22.0451], device='cuda:0')]
2023-09-09 09:29:46,408: epoch:1 step:11 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,411: epoch:1 step:11 rank:0 || image:[tensor([30.0050, 30.0051], device='cuda:0'), tensor([20.0500, 20.0501], device='cuda:0')] || in_text:[tensor([31.0050, 31.0051], device='cuda:0'), tensor([21.0500, 21.0501], device='cuda:0')] || out_text:[tensor([32.0050, 32.0051], device='cuda:0'), tensor([22.0500, 22.0501], device='cuda:0')]
2023-09-09 09:29:46,415: epoch:1 step:12 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,418: epoch:1 step:12 rank:0 || image:[tensor([30.0065, 30.0066], device='cuda:0'), tensor([20.0550, 20.0551], device='cuda:0')] || in_text:[tensor([31.0065, 31.0066], device='cuda:0'), tensor([21.0550, 21.0551], device='cuda:0')] || out_text:[tensor([32.0065, 32.0066], device='cuda:0'), tensor([22.0550, 22.0551], device='cuda:0')]
2023-09-09 09:29:46,422: epoch:1 step:13 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,425: epoch:1 step:13 rank:0 || image:[tensor([30.0080, 30.0081], device='cuda:0'), tensor([20.0600, 20.0601], device='cuda:0')] || in_text:[tensor([31.0080, 31.0081], device='cuda:0'), tensor([21.0600, 21.0601], device='cuda:0')] || out_text:[tensor([32.0080, 32.0081], device='cuda:0'), tensor([22.0600, 22.0601], device='cuda:0')]
2023-09-09 09:29:46,429: epoch:1 step:14 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,432: epoch:1 step:14 rank:0 || image:[tensor([30.0095, 30.0096], device='cuda:0'), tensor([20.0650, 20.0651], device='cuda:0')] || in_text:[tensor([31.0095, 31.0096], device='cuda:0'), tensor([21.0650, 21.0651], device='cuda:0')] || out_text:[tensor([32.0095, 32.0096], device='cuda:0'), tensor([22.0650, 22.0651], device='cuda:0')]
2023-09-09 09:29:46,435: epoch:1 step:15 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,437: epoch:1 step:15 rank:0 || image:[tensor([30.0110, 30.0111], device='cuda:0'), tensor([20.0700, 20.0701], device='cuda:0')] || in_text:[tensor([31.0110, 31.0111], device='cuda:0'), tensor([21.0700, 21.0701], device='cuda:0')] || out_text:[tensor([32.0110, 32.0111], device='cuda:0'), tensor([22.0700, 22.0701], device='cuda:0')]
2023-09-09 09:29:46,440: epoch:1 step:16 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,442: epoch:1 step:16 rank:0 || image:[tensor([30.0125, 30.0126], device='cuda:0'), tensor([20.0750, 20.0751], device='cuda:0')] || in_text:[tensor([31.0125, 31.0126], device='cuda:0'), tensor([21.0750, 21.0751], device='cuda:0')] || out_text:[tensor([32.0125, 32.0126], device='cuda:0'), tensor([22.0750, 22.0751], device='cuda:0')]
2023-09-09 09:29:46,445: epoch:1 step:17 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,448: epoch:1 step:17 rank:0 || image:[tensor([30.0140, 30.0141], device='cuda:0'), tensor([20.0800, 20.0801], device='cuda:0')] || in_text:[tensor([31.0140, 31.0141], device='cuda:0'), tensor([21.0800, 21.0801], device='cuda:0')] || out_text:[tensor([32.0140, 32.0141], device='cuda:0'), tensor([22.0800, 22.0801], device='cuda:0')]
2023-09-09 09:29:46,450: epoch:1 step:18 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,453: epoch:1 step:18 rank:0 || image:[tensor([30.0155, 30.0156], device='cuda:0'), tensor([20.0850, 20.0851], device='cuda:0')] || in_text:[tensor([31.0155, 31.0156], device='cuda:0'), tensor([21.0850, 21.0851], device='cuda:0')] || out_text:[tensor([32.0155, 32.0156], device='cuda:0'), tensor([22.0850, 22.0851], device='cuda:0')]
2023-09-09 09:29:46,455: epoch:1 step:19 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,458: epoch:1 step:19 rank:0 || image:[tensor([30.0170, 30.0171], device='cuda:0'), tensor([20.0900, 20.0901], device='cuda:0')] || in_text:[tensor([31.0170, 31.0171], device='cuda:0'), tensor([21.0900, 21.0901], device='cuda:0')] || out_text:[tensor([32.0170, 32.0171], device='cuda:0'), tensor([22.0900, 22.0901], device='cuda:0')]
2023-09-09 09:29:46,459: epoch:1 step:20 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,462: epoch:1 step:20 rank:0 || image:[tensor([30.0185, 30.0186], device='cuda:0'), tensor([20.0950, 20.0951], device='cuda:0')] || in_text:[tensor([31.0185, 31.0186], device='cuda:0'), tensor([21.0950, 21.0951], device='cuda:0')] || out_text:[tensor([32.0185, 32.0186], device='cuda:0'), tensor([22.0950, 22.0951], device='cuda:0')]
2023-09-09 09:29:46,463: epoch:1 step:21 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,465: epoch:1 step:21 rank:0 || image:[tensor([30.0200, 30.0201], device='cuda:0'), tensor([20.1000, 20.1001], device='cuda:0')] || in_text:[tensor([31.0200, 31.0201], device='cuda:0'), tensor([21.1000, 21.1001], device='cuda:0')] || out_text:[tensor([32.0200, 32.0201], device='cuda:0'), tensor([22.1000, 22.1001], device='cuda:0')]
2023-09-09 09:29:46,466: epoch:1 step:22 rank:0 || batch_size = image:torch.Size([65, 1]) || in_text:torch.Size([65, 1]) || out_text:torch.Size([65, 1])
2023-09-09 09:29:46,469: epoch:1 step:22 rank:0 || image:[tensor([30.0215, 30.0216], device='cuda:0'), tensor([20.1050, 20.1051], device='cuda:0')] || in_text:[tensor([31.0215, 31.0216], device='cuda:0'), tensor([21.1050, 21.1051], device='cuda:0')] || out_text:[tensor([32.0215, 32.0216], device='cuda:0'), tensor([22.1050, 22.1051], device='cuda:0')]
Traceback (most recent call last):
  File "/home/w49009a/omote/KLab_MultiModalModel/multi_task_train/multi_task_train_multi_node.py", line 400, in <module>
    train()
  File "/home/w49009a/omote/KLab_MultiModalModel/multi_task_train/multi_task_train_multi_node.py", line 304, in train
    dist.all_reduce(train_loss, op=dist.ReduceOp.SUM)
  File "/home/w49009a/omote/KLab_MultiModalModel/.venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1451, in wrapper
    return func(*args, **kwargs)
  File "/home/w49009a/omote/KLab_MultiModalModel/.venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1686, in all_reduce
    _check_single_tensor(tensor, "tensor")
  File "/home/w49009a/omote/KLab_MultiModalModel/.venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 586, in _check_single_tensor
    raise RuntimeError(
RuntimeError: Invalid function argument. Expected parameter `tensor` to be of type torch.Tensor.
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[46850,1],0]
  Exit code:    1
--------------------------------------------------------------------------
